<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Why would I use DuckDB for that? | Robin's blog</title>
<meta name=keywords content="data,duckdb,postgres,sql"><meta name=description content="The past few weeks I&rsquo;ve been experimenting with DuckDB, and as a consequence I&rsquo;ve ended up talking about it a lot as well. I&rsquo;m not going to lie, I really like it! However, experienced programmers will rightly be skeptical to add new technology that overlaps with something that already works great. So why not just use postgres?
Well, I really like postgres too, and I think you should consider just using it! But despite both of these technologies being all about tabular data, they&rsquo;re not really for the same kinds of problems. I think DuckDB is primarily an analysis or ELT tool, and it really excels in this space. postgres can do a lot of the things that DuckDB can do, but not nearly as fast or easily. I wouldn&rsquo;t want to use DuckDB for a transactional workload, so it&rsquo;s not going to replace postgres for anything that I use it for."><meta name=author content="Robin Kåveland"><link rel=canonical href=https://kaveland.no/posts/2025-03-02-can-i-just-use-postgres/><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=https://kaveland.no/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://kaveland.no/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://kaveland.no/favicon-32x32.png><link rel=apple-touch-icon href=https://kaveland.no/apple-touch-icon.png><link rel=mask-icon href=https://kaveland.no/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://kaveland.no/posts/2025-03-02-can-i-just-use-postgres/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script defer data-domain=kaveland.no src=https://plausible.io/js/script.js></script><meta property="og:title" content="Why would I use DuckDB for that?"><meta property="og:description" content="The past few weeks I&rsquo;ve been experimenting with DuckDB, and as a consequence I&rsquo;ve ended up talking about it a lot as well. I&rsquo;m not going to lie, I really like it! However, experienced programmers will rightly be skeptical to add new technology that overlaps with something that already works great. So why not just use postgres?
Well, I really like postgres too, and I think you should consider just using it! But despite both of these technologies being all about tabular data, they&rsquo;re not really for the same kinds of problems. I think DuckDB is primarily an analysis or ELT tool, and it really excels in this space. postgres can do a lot of the things that DuckDB can do, but not nearly as fast or easily. I wouldn&rsquo;t want to use DuckDB for a transactional workload, so it&rsquo;s not going to replace postgres for anything that I use it for."><meta property="og:type" content="article"><meta property="og:url" content="https://kaveland.no/posts/2025-03-02-can-i-just-use-postgres/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-03-02T00:00:00+00:00"><meta property="article:modified_time" content="2025-03-02T00:00:00+00:00"><meta property="og:site_name" content="Robin's blog"><meta name=twitter:card content="summary"><meta name=twitter:title content="Why would I use DuckDB for that?"><meta name=twitter:description content="The past few weeks I&rsquo;ve been experimenting with DuckDB, and as a consequence I&rsquo;ve ended up talking about it a lot as well. I&rsquo;m not going to lie, I really like it! However, experienced programmers will rightly be skeptical to add new technology that overlaps with something that already works great. So why not just use postgres?
Well, I really like postgres too, and I think you should consider just using it! But despite both of these technologies being all about tabular data, they&rsquo;re not really for the same kinds of problems. I think DuckDB is primarily an analysis or ELT tool, and it really excels in this space. postgres can do a lot of the things that DuckDB can do, but not nearly as fast or easily. I wouldn&rsquo;t want to use DuckDB for a transactional workload, so it&rsquo;s not going to replace postgres for anything that I use it for."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://kaveland.no/posts/"},{"@type":"ListItem","position":2,"name":"Why would I use DuckDB for that?","item":"https://kaveland.no/posts/2025-03-02-can-i-just-use-postgres/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Why would I use DuckDB for that?","name":"Why would I use DuckDB for that?","description":"The past few weeks I\u0026rsquo;ve been experimenting with DuckDB, and as a consequence I\u0026rsquo;ve ended up talking about it a lot as well. I\u0026rsquo;m not going to lie, I really like it! However, experienced programmers will rightly be skeptical to add new technology that overlaps with something that already works great. So why not just use postgres?\nWell, I really like postgres too, and I think you should consider just using it! But despite both of these technologies being all about tabular data, they\u0026rsquo;re not really for the same kinds of problems. I think DuckDB is primarily an analysis or ELT tool, and it really excels in this space. postgres can do a lot of the things that DuckDB can do, but not nearly as fast or easily. I wouldn\u0026rsquo;t want to use DuckDB for a transactional workload, so it\u0026rsquo;s not going to replace postgres for anything that I use it for.\n","keywords":["data","duckdb","postgres","sql"],"articleBody":"The past few weeks I’ve been experimenting with DuckDB, and as a consequence I’ve ended up talking about it a lot as well. I’m not going to lie, I really like it! However, experienced programmers will rightly be skeptical to add new technology that overlaps with something that already works great. So why not just use postgres?\nWell, I really like postgres too, and I think you should consider just using it! But despite both of these technologies being all about tabular data, they’re not really for the same kinds of problems. I think DuckDB is primarily an analysis or ELT tool, and it really excels in this space. postgres can do a lot of the things that DuckDB can do, but not nearly as fast or easily. I wouldn’t want to use DuckDB for a transactional workload, so it’s not going to replace postgres for anything that I use it for.\nI want to do some basic tests, verify that my understanding is correct and be able to back up my claims with some numbers. So I’ve downloaded some data of from data.entur.no again, namely the Norwegian national real-time recordings for public transit data for January and February 2025. I wrote about this data set in an earlier blogpost, if you want to learn more about it.\nIf you want to follow along, you can download the DuckDB file from here (5GB download).\nThis is a jupyter notebook, so we’ll be mixing code and prose, and show lots of output from programs. Let’s get our bearings quickly:\nimport duckdb db = duckdb.connect('all.db') %load_ext sql %config SqlMagic.displaylimit=50 %sql db --alias duckdb %sql select count() from arrivals; Running query in 'duckdb'\ncount_star() 85079666 So we have about 85 million rows in here, on this schema:\n%%sql DESCRIBE ARRIVALS Running query in 'duckdb'\ncolumn_name column_type null key default extra recordedAtTime TIMESTAMP WITH TIME ZONE YES None None None lineRef VARCHAR YES None None None directionRef VARCHAR YES None None None operatingDate DATE YES None None None vehicleMode VARCHAR YES None None None extraJourney BOOLEAN YES None None None journeyCancellation BOOLEAN YES None None None stopPointRef VARCHAR YES None None None sequenceNr BIGINT YES None None None stopPointName VARCHAR YES None None None originName VARCHAR YES None None None destinationName VARCHAR YES None None None extraCall BOOLEAN YES None None None stopCancellation BOOLEAN YES None None None estimated BOOLEAN YES None None None aimedArrivalTime TIMESTAMP WITH TIME ZONE YES None None None arrivalTime TIMESTAMP WITH TIME ZONE YES None None None aimedDepartureTime TIMESTAMP WITH TIME ZONE YES None None None departureTime TIMESTAMP WITH TIME ZONE YES None None None datedServiceJourneyId VARCHAR YES None None None dataSource VARCHAR YES None None None dataSourceName VARCHAR YES None None None This database file is about 5GB:\n!du -hs all.db 5,1G\tall.db I want to put this in a postgres database, so we can do some comparisons. I’ve set up postgres-17 on my machine, from the postgres apt. I’m going to put the binaries on PATH, so we can easily make our own postgres instance. This machine has 64GB RAM, and we’re going to be the only ones using it, so we can give postgres a lot of resources.\nimport os import string import random os.environ['PATH'] = '/usr/lib/postgresql/17/bin:' + os.environ['PATH'] # Generate a random password and set it in the env so that all the postgres libs will find it. os.environ['PGPASSWORD'] = ''.join(random.choices(string.ascii_letters + string.digits, k=20)) Having done that, we can use initdb to set up a postgres cluster/instance in the pgtemp directory under the current working directory:\n%%bash # Create a databasecluster where: # superuser is named postgres # each connection/worker can use 8GB RAM # the buffer manager can use 24GB RAM to cache tables # in the pgtemp directory initdb -U postgres \\ --set work_mem=8GB \\ --set shared_buffers=24GB \\ --set maintenance_work_mem=8GB \\ --set listen_addresses=127.0.0.1 \\ --set port=5433 \\ --set unix_socket_directories=\"$(pwd)/pgsockets\" \\ -D pgtemp ... Success. You can now start the database server using: pg_ctl -D pgtemp -l logfile start ... Let’s double-check the settings we got, so that we won’t be surprised later if we somehow got the default work_mem:\n!grep -E 'work_mem|shared_buffers|listen' pgtemp/postgresql.conf listen_addresses = '127.0.0.1'\t# what IP address(es) to listen on; shared_buffers = 24GB\t# min 128kB work_mem = 8GB\t# min 64kB #hash_mem_multiplier = 2.0\t# 1-1000.0 multiplier on hash table work_mem maintenance_work_mem = 8GB\t# min 64kB #autovacuum_work_mem = -1\t# min 64kB, or -1 to use maintenance_work_mem #logical_decoding_work_mem = 64MB\t# min 64kB #wal_buffers = -1\t# min 32kB, -1 sets based on shared_buffers Looks good, let’s start it!\n!mkdir -p pgsockets !pg_ctl -D pgtemp -l pg.log start waiting for server to start.... done server started Now we have a postgres on 127.0.0.1:5433! Let’s attach DuckDB to it so we can easily put the data in there. We will create an unlogged table that doesn’t generate transaction logs, since they’re not useful for this experiment. It should make it a bit faster to insert data into it. It also means that this table would essentially be lost if our postgres crashed, so think carefully before doing this on something important.\n%%sql ATTACH 'dbname=postgres user=postgres host=127.0.0.1 port=5433' AS pgtemp (TYPE postgres); CREATE TABLE pgtemp.arrivals( recordedAtTime TIMESTAMP WITH TIME ZONE, lineRef VARCHAR, directionRef VARCHAR, operatingDate DATE, vehicleMode VARCHAR, extraJourney BOOLEAN, journeyCancellation BOOLEAN, stopPointRef VARCHAR, sequenceNr BIGINT, stopPointName VARCHAR, originName VARCHAR, destinationName VARCHAR, extraCall BOOLEAN, stopCancellation BOOLEAN, estimated BOOLEAN, aimedArrivalTime TIMESTAMP WITH TIME ZONE, arrivalTime TIMESTAMP WITH TIME ZONE, aimedDepartureTime TIMESTAMP WITH TIME ZONE, departureTime TIMESTAMP WITH TIME ZONE, datedServiceJourneyId VARCHAR, dataSource VARCHAR, dataSourceName VARCHAR); Running query in 'duckdb'\nLet’s make it unlogged:\n%%sql CALL postgres_execute('pgtemp', 'ALTER TABLE arrivals SET UNLOGGED;') Running query in 'duckdb'\nSuccess Since our table schemas match, we should be able to use DuckDB to bulkload this efficiently. Let’s give it a go:\n%%sql INSERT INTO pgtemp.arrivals BY NAME SELECT * FROM arrivals; Running query in 'duckdb'\nCount 85079666 Okay, the first thing I want to know is the size of the database after doing this, let’s check:\n!du -hs pgtemp 18G\tpgtemp This is not surprising to me, columnar storage formats are much easier to compress efficiently than row storage formats, like the one used by postgres. This should fit in memory for postgres, it has 24GB RAM for shared buffers (and a generous 8GB for sorting and things like that). Let’s time some basic operations in DuckDB vs postgres. We will limit DuckDB to 16GB RAM, so my machine can have something left over for running… everything else.\n# limits for DuckDB %sql set memory_limit = '16GB'; %sql set threads = 11; -- CPU has 12 physical cores, Ryzen 9 5900X. %time db.sql(\"select dataSource, count(*) from arrivals group by dataSource\").df() %time db.sql(\"\"\"call postgres_query('pgtemp', 'select \"dataSource\", count(*) from arrivals group by \"dataSource\"')\"\"\").df() CPU times: user 316 ms, sys: 11.3 ms, total: 327 ms Wall time: 31.6 ms CPU times: user 11.3 s, sys: 854 μs, total: 11.3 s Wall time: 11.3 s I discarded the result set output from this, keeping only the execution times. For this very simple example, DuckDB can do it in 31.6ms and postgres needs 11.3 seconds.\nThis is a very unfair comparison, though. In this particular instance, DuckDB looks only at 1 column, and it is probably dictionary-encoded and run length encoded, similarly to how Arrow and Parquet does it. You can read a bit more about that here and here. This kind of query and data distribution is essentially a best-case for columnar storage formats. An index would help postgres here, but it would likely be significantly bigger than the column DuckDB has stored, and therefore still slower.\nIt may be much more fair to try to do a group by on a column where such shortcuts aren’t possible. Let’s count registrations by hour of day, which forces both implementations to look at all values of the recordedAtTime column.\nq = 'select count(*), extract(hour from \"recordedAtTime\") as hour from arrivals group by 2' %time db.sql(q).df() %time db.sql(f\"call postgres_query('pgtemp', '{q}')\").df() CPU times: user 18 s, sys: 0 ns, total: 18 s Wall time: 1.65 s CPU times: user 5.97 s, sys: 0 ns, total: 5.97 s Wall time: 5.97 s This time, the difference is much less drastic. DuckDB needs 1.65s and postgres can do it in 6s. For this query, DuckDB needed to investigate every value in the column, there’s much less work that it can simply skip. Looking at the CPU time information, it seems obvious that DuckDB is using much more CPU to do this calculation than postgres, due to parallelization.\nLet’s try one that is a little tougher still. Let’s use a window function to calculate the time from arrival at one stop, to the next and calculate some nonsense statistics about it. This will force both databases to do a lot of work using several columns. We may be able to make useful indexes for postgres here, but we’ll try without first (I am expecting postgres to summarily lose this one without an index).\nq = ''' with times as ( select extract(epoch from lead(\"arrivalTime\", 1) over (partition by \"datedServiceJourneyId\" order by \"sequenceNr\") - \"arrivalTime\" ) as timedelta from arrivals ) select max(timedelta), min(timedelta), sum(timedelta) / count(*) -- avg in postgres and mean in duckdb from times ''' %time db.sql(q).df() %time db.sql(f\"call postgres_query('pgtemp', '{q}')\").df() CPU times: user 2min 40s, sys: 9.72 s, total: 2min 50s Wall time: 15.7 s CPU times: user 8min 15s, sys: 52.2 ms, total: 8min 15s Wall time: 8min 15s Wow, that’s a big difference. DuckDB spent 15.7s and postgres spent 8 mins 15s. I am not sure why the difference is so big in this case. Even a table scan should be quite quick for postgres now, the data is certainly in RAM already. This difference is so large that I can’t explain it without involving disk usage.\nIn this case, it would have been much faster to pull all the data out from postgres and into DuckDB and do the aggregation there. I’m betting we can help postgres by making an index that matches the partition of the window function. Let’s do that.\nindex = 'create index on arrivals(\"datedServiceJourneyId\", \"sequenceNr\");' %time db.execute(f\"call postgres_execute('pgtemp', '{index}');\") CPU times: user 3min 3s, sys: 954 ms, total: 3min 4s Wall time: 3min 3s 3 minutes, less time than running the query originally. Let’s try the query one more time:\n%time db.sql(f\"call postgres_query('pgtemp', '{q}')\").df() CPU times: user 8min 16s, sys: 432 ms, total: 8min 17s Wall time: 8min 16s Right, the index was not useful. Perhaps because the table fits in memory anyway. I made sure to ANALYZE; and try again, just in case. On disk, this index is larger than the entire DuckDB file, creating it increased the size of the pgtemp postgres cluster to 25GB:\n!du -hs pgtemp 25G\tpgtemp One variation that we haven’t tried yet, is to just run the query in DuckDB, but against the postgres table (meaning DuckDB will have to delegate some work to postgres, or copy out all the data).\n%time db.sql(q.replace(\"arrivals\", \"pgtemp.arrivals\")).df() CPU times: user 3min, sys: 13.6 s, total: 3min 14s Wall time: 25.7 s Right, that’s very interesting, that’s 25.7s compared to the 8 minutes of running purely in postgres or the 13.4s of running purely against DuckDB. This would create load and IO on the postgres database server, naturally, but maybe that’s a good way to offload the heavy computational work onto the applicationserver?\nI’m going to go look some more into what’s happening in postgres here, it does not make sense to me that it can take 8 minutes to run this query if everything’s in memory. I’ll head over to psql and check out what explain (analyze on, buffers on) tells me.\npostgres=# explain (analyze on, buffers on) with times as ( select extract(epoch from lead(\"arrivalTime\", 1) over (partition by \"datedServiceJourneyId\" order by \"sequenceNr\") - \"arrivalTime\" ) as timedelta from arrivals ) select max(timedelta), min(timedelta), sum(timedelta) / count(*) -- avg in postgres and mean in duckdb from times; QUERY PLAN ----------------------------------------------------------------------------------------------------------------------------------------------- Aggregate (cost=18207075.69..18207075.71 rows=1 width=96) (actual time=506560.516..506560.517 rows=1 loops=1) Buffers: shared hit=2729 read=2314831, temp read=813011 written=813012 -\u003e WindowAgg (cost=14377525.67..16505053.45 rows=85101112 width=90) (actual time=467725.139..501383.481 rows=85079666 loops=1) Buffers: shared hit=2729 read=2314831, temp read=813011 written=813012 -\u003e Sort (cost=14377525.65..14590278.43 rows=85101112 width=66) (actual time=467725.100..474901.976 rows=85079666 loops=1) Sort Key: arrivals.\"datedServiceJourneyId\", arrivals.\"sequenceNr\" Sort Method: external merge Disk: 6504088kB Buffers: shared hit=2729 read=2314831, temp read=813011 written=813012 -\u003e Seq Scan on arrivals (cost=0.00..3168571.12 rows=85101112 width=66) (actual time=199.763..17347.756 rows=85079666 loops=1) Buffers: shared hit=2729 read=2314831 Planning: Buffers: shared hit=22 Planning Time: 0.371 ms JIT: Functions: 11 Options: Inlining true, Optimization true, Expressions true, Deforming true Timing: Generation 0.608 ms (Deform 0.255 ms), Inlining 64.518 ms, Optimization 68.888 ms, Emission 66.374 ms, Total 200.389 ms Execution Time: 507455.248 ms Aha, so it’s sorting on disk. That means it may help to increase work_mem. I’ll try to double it to 16GB with set work_mem='16GB'; (and close some applications on this machine). I will also create an index that includes all the 3 columns this query uses, to try to get an Index Only Scan:\npostgres=# create index on arrivals(\"datedServiceJourneyId\", \"sequenceNr\", \"arrivalTime\"); CREATE INDEX postgres=# explain (analyze on, buffers on) with times as ( select extract(epoch from lead(\"arrivalTime\", 1) over (partition by \"datedServiceJourneyId\" order by \"sequenceNr\") - \"arrivalTime\" ) as timedelta from arrivals ) select max(timedelta), min(timedelta), sum(timedelta) / count(*) -- avg in postgres and mean in duckdb from times; QUERY PLAN ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- Aggregate (cost=8735893.91..8735893.93 rows=1 width=96) (actual time=46947.869..46947.870 rows=1 loops=1) Buffers: shared hit=51347699 read=947841 -\u003e WindowAgg (cost=0.77..7034300.63 rows=85079664 width=90) (actual time=61.489..41859.920 rows=85079666 loops=1) Buffers: shared hit=51347699 read=947841 -\u003e Index Only Scan using \"arrivals_datedServiceJourneyId_sequenceNr_arrivalTime_idx\" on arrivals (cost=0.69..5120008.19 rows=85079664 width=66) (actual time=61.471..12268.748 rows=85079666 loops=1) Heap Fetches: 0 Buffers: shared hit=51347699 read=947841 Planning: Buffers: shared hit=22 read=1 dirtied=2 Planning Time: 14.759 ms JIT: Functions: 10 Options: Inlining true, Optimization true, Expressions true, Deforming true Timing: Generation 0.499 ms (Deform 0.116 ms), Inlining 11.793 ms, Optimization 28.170 ms, Emission 21.494 ms, Total 61.955 ms Execution Time: 46950.351 ms (15 rows) That’s more like it. So if we back the query with an appropriate index, postgres can run this query in 47s, which is quite close to DuckDB, considering that it doesn’t use all my cores. This index is 7504MB, though, and took some minutes to create. In other words, I need to know that I must back this query with an index to get good performance. If this was a database server with some transactional workload, it could have consequences to run the query without the index. We’re also relying on the index being in memory to get good performance here.\nConclusion Here’s the short summary:\nDuckDB can’t do concurrent write transactions. postgres is great for that! postgres can parallelize queries, but DuckDB does this much more aggressively. DuckDB is more forgiving on analytical queries if you haven’t set up the correct indexes. DuckDB is likely to be much faster for analytical queries on big data sets. DuckDB stores data much more compactly. postgres is great for sharing compute resources fairly between many concurrent users. But they seem to work great together too! I’m going to clean up my mess here and call it a day. I do think it’s probably true that postgres can do almost everything that DuckDB can do. But I can definitely see a case for having both, they complement each others capabilities really well.\n!pg_ctl stop -D pgtemp !rm -rf pgtemp waiting for server to shut down...... done server stopped Thanks for reading!\n","wordCount":"2570","inLanguage":"en","datePublished":"2025-03-02T00:00:00Z","dateModified":"2025-03-02T00:00:00Z","author":{"@type":"Person","name":"Robin Kåveland"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://kaveland.no/posts/2025-03-02-can-i-just-use-postgres/"},"publisher":{"@type":"Organization","name":"Robin's blog","logo":{"@type":"ImageObject","url":"https://kaveland.no/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://kaveland.no/ accesskey=h title="Robin's blog (Alt + H)">Robin's blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://kaveland.no/about/ title=about><span>about</span></a></li><li><a href=https://kaveland.no/projects/ title=projects><span>projects</span></a></li><li><a href=https://kaveland.no/eugene/ title=eugene><span>eugene</span></a></li><li><a href=https://kaveland.no/thumper/ title=thumper><span>thumper</span></a></li><li><a href=https://kaveland.no/tags/ title=tags><span>tags</span></a></li><li><a href=https://kaveland.no/archives/ title=archives><span>archives</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://kaveland.no/>Home</a>&nbsp;»&nbsp;<a href=https://kaveland.no/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Why would I use DuckDB for that?</h1><div class=post-meta><span title='2025-03-02 00:00:00 +0000 UTC'>March 2, 2025</span>&nbsp;·&nbsp;13 min&nbsp;·&nbsp;2570 words&nbsp;·&nbsp;Robin Kåveland&nbsp;|&nbsp;<a href=https://github.com/kaaveland/kaaveland.github.io/content/posts/2025-03-02-can-i-just-use-postgres.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#conclusion>Conclusion</a></li></ul></nav></div></details></div><div class=post-content><p>The past few weeks I&rsquo;ve been experimenting with <a href=https://duckdb.org/>DuckDB</a>, and as a consequence I&rsquo;ve ended up talking about it a lot as well. I&rsquo;m not going to lie, I really like it! However, experienced programmers will rightly be skeptical to add new technology that overlaps with something that already works great. So why not just use postgres?</p><p>Well, I really like postgres too, and I think you should consider just using it! But despite both of these technologies being all about tabular data, they&rsquo;re not really for the same kinds of problems. I think DuckDB is primarily an analysis or ELT tool, and it really excels in this space. postgres <em>can</em> do a lot of the things that DuckDB can do, but not nearly as fast or easily. I wouldn&rsquo;t want to use DuckDB for a transactional workload, so it&rsquo;s not going to replace postgres for anything that I use it for.</p><p>I want to do some basic tests, verify that my understanding is correct and be able to back up my claims with some numbers. So I&rsquo;ve downloaded some data of from <a href=https://data.entur.no/>data.entur.no</a> again, namely the Norwegian national real-time recordings for public transit data for January and February 2025. I wrote about this data set in <a href=https://arktekk.no/blogs/2025_entur_realtimedataset>an earlier blogpost</a>, if you want to learn more about it.</p><p>If you want to follow along, you can download the DuckDB file from <a href=https://kaaveland-bus-eta-data.hel1.your-objectstorage.com/all.db>here</a> (5GB download).</p><p>This is a jupyter notebook, so we&rsquo;ll be mixing code and prose, and show lots of output from programs. Let&rsquo;s get our bearings quickly:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>duckdb</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>db</span> <span class=o>=</span> <span class=n>duckdb</span><span class=o>.</span><span class=n>connect</span><span class=p>(</span><span class=s1>&#39;all.db&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>%</span><span class=n>load_ext</span> <span class=n>sql</span>
</span></span><span class=line><span class=cl><span class=o>%</span><span class=n>config</span> <span class=n>SqlMagic</span><span class=o>.</span><span class=n>displaylimit</span><span class=o>=</span><span class=mi>50</span>
</span></span><span class=line><span class=cl><span class=o>%</span><span class=n>sql</span> <span class=n>db</span> <span class=o>--</span><span class=n>alias</span> <span class=n>duckdb</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>%</span><span class=n>sql</span> <span class=n>select</span> <span class=n>count</span><span class=p>()</span> <span class=kn>from</span> <span class=nn>arrivals</span><span class=p>;</span>
</span></span></code></pre></div><p><span style=none>Running query in 'duckdb'</span></p><table><thead><tr><th>count_star()</th></tr></thead><tbody><tr><td>85079666</td></tr></tbody></table><p>So we have about 85 million rows in here, on this schema:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=o>%%</span><span class=k>sql</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>DESCRIBE</span><span class=w> </span><span class=n>ARRIVALS</span><span class=w>
</span></span></span></code></pre></div><p><span style=none>Running query in 'duckdb'</span></p><table><thead><tr><th>column_name</th><th>column_type</th><th>null</th><th>key</th><th>default</th><th>extra</th></tr></thead><tbody><tr><td>recordedAtTime</td><td>TIMESTAMP WITH TIME ZONE</td><td>YES</td><td>None</td><td>None</td><td>None</td></tr><tr><td>lineRef</td><td>VARCHAR</td><td>YES</td><td>None</td><td>None</td><td>None</td></tr><tr><td>directionRef</td><td>VARCHAR</td><td>YES</td><td>None</td><td>None</td><td>None</td></tr><tr><td>operatingDate</td><td>DATE</td><td>YES</td><td>None</td><td>None</td><td>None</td></tr><tr><td>vehicleMode</td><td>VARCHAR</td><td>YES</td><td>None</td><td>None</td><td>None</td></tr><tr><td>extraJourney</td><td>BOOLEAN</td><td>YES</td><td>None</td><td>None</td><td>None</td></tr><tr><td>journeyCancellation</td><td>BOOLEAN</td><td>YES</td><td>None</td><td>None</td><td>None</td></tr><tr><td>stopPointRef</td><td>VARCHAR</td><td>YES</td><td>None</td><td>None</td><td>None</td></tr><tr><td>sequenceNr</td><td>BIGINT</td><td>YES</td><td>None</td><td>None</td><td>None</td></tr><tr><td>stopPointName</td><td>VARCHAR</td><td>YES</td><td>None</td><td>None</td><td>None</td></tr><tr><td>originName</td><td>VARCHAR</td><td>YES</td><td>None</td><td>None</td><td>None</td></tr><tr><td>destinationName</td><td>VARCHAR</td><td>YES</td><td>None</td><td>None</td><td>None</td></tr><tr><td>extraCall</td><td>BOOLEAN</td><td>YES</td><td>None</td><td>None</td><td>None</td></tr><tr><td>stopCancellation</td><td>BOOLEAN</td><td>YES</td><td>None</td><td>None</td><td>None</td></tr><tr><td>estimated</td><td>BOOLEAN</td><td>YES</td><td>None</td><td>None</td><td>None</td></tr><tr><td>aimedArrivalTime</td><td>TIMESTAMP WITH TIME ZONE</td><td>YES</td><td>None</td><td>None</td><td>None</td></tr><tr><td>arrivalTime</td><td>TIMESTAMP WITH TIME ZONE</td><td>YES</td><td>None</td><td>None</td><td>None</td></tr><tr><td>aimedDepartureTime</td><td>TIMESTAMP WITH TIME ZONE</td><td>YES</td><td>None</td><td>None</td><td>None</td></tr><tr><td>departureTime</td><td>TIMESTAMP WITH TIME ZONE</td><td>YES</td><td>None</td><td>None</td><td>None</td></tr><tr><td>datedServiceJourneyId</td><td>VARCHAR</td><td>YES</td><td>None</td><td>None</td><td>None</td></tr><tr><td>dataSource</td><td>VARCHAR</td><td>YES</td><td>None</td><td>None</td><td>None</td></tr><tr><td>dataSourceName</td><td>VARCHAR</td><td>YES</td><td>None</td><td>None</td><td>None</td></tr></tbody></table><p>This database file is about 5GB:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=err>!</span><span class=n>du</span> <span class=o>-</span><span class=n>hs</span> <span class=nb>all</span><span class=o>.</span><span class=n>db</span>
</span></span></code></pre></div><pre><code>5,1G	all.db
</code></pre><p>I want to put this in a postgres database, so we can do some comparisons. I&rsquo;ve set up postgres-17 on my machine, from the <a href=https://wiki.postgresql.org/wiki/Apt>postgres apt</a>. I&rsquo;m going to put the binaries on PATH, so we can easily make our own postgres instance. This machine has 64GB RAM, and we&rsquo;re going to be the only ones using it, so we can give postgres a lot of resources.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>string</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>random</span>
</span></span><span class=line><span class=cl><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;PATH&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=s1>&#39;/usr/lib/postgresql/17/bin:&#39;</span> <span class=o>+</span> <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;PATH&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=c1># Generate a random password and set it in the env so that all the postgres libs will find it.</span>
</span></span><span class=line><span class=cl><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;PGPASSWORD&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=s1>&#39;&#39;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>random</span><span class=o>.</span><span class=n>choices</span><span class=p>(</span><span class=n>string</span><span class=o>.</span><span class=n>ascii_letters</span> <span class=o>+</span> <span class=n>string</span><span class=o>.</span><span class=n>digits</span><span class=p>,</span> <span class=n>k</span><span class=o>=</span><span class=mi>20</span><span class=p>))</span>
</span></span></code></pre></div><p>Having done that, we can use <code>initdb</code> to set up a postgres cluster/instance in the <code>pgtemp</code> directory under the current working directory:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>%%bash
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Create a databasecluster where:</span>
</span></span><span class=line><span class=cl><span class=c1># superuser is named postgres</span>
</span></span><span class=line><span class=cl><span class=c1># each connection/worker can use 8GB RAM</span>
</span></span><span class=line><span class=cl><span class=c1># the buffer manager can use 24GB RAM to cache tables</span>
</span></span><span class=line><span class=cl><span class=c1># in the pgtemp directory</span>
</span></span><span class=line><span class=cl>initdb -U postgres <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --set <span class=nv>work_mem</span><span class=o>=</span>8GB <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --set <span class=nv>shared_buffers</span><span class=o>=</span>24GB <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --set <span class=nv>maintenance_work_mem</span><span class=o>=</span>8GB <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --set <span class=nv>listen_addresses</span><span class=o>=</span>127.0.0.1 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --set <span class=nv>port</span><span class=o>=</span><span class=m>5433</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --set <span class=nv>unix_socket_directories</span><span class=o>=</span><span class=s2>&#34;</span><span class=k>$(</span><span class=nb>pwd</span><span class=k>)</span><span class=s2>/pgsockets&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  -D pgtemp
</span></span></code></pre></div><pre><code>...
Success. You can now start the database server using:

    pg_ctl -D pgtemp -l logfile start
...
</code></pre><p>Let&rsquo;s double-check the settings we got, so that we won&rsquo;t be surprised later if we somehow got the default <code>work_mem</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=err>!</span><span class=n>grep</span> <span class=o>-</span><span class=n>E</span> <span class=s1>&#39;work_mem|shared_buffers|listen&#39;</span> <span class=n>pgtemp</span><span class=o>/</span><span class=n>postgresql</span><span class=o>.</span><span class=n>conf</span>
</span></span></code></pre></div><pre><code>listen_addresses = '127.0.0.1'		# what IP address(es) to listen on;
shared_buffers = 24GB			# min 128kB
work_mem = 8GB				# min 64kB
#hash_mem_multiplier = 2.0		# 1-1000.0 multiplier on hash table work_mem
maintenance_work_mem = 8GB		# min 64kB
#autovacuum_work_mem = -1		# min 64kB, or -1 to use maintenance_work_mem
#logical_decoding_work_mem = 64MB	# min 64kB
#wal_buffers = -1			# min 32kB, -1 sets based on shared_buffers
</code></pre><p>Looks good, let&rsquo;s start it!</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=err>!</span><span class=n>mkdir</span> <span class=o>-</span><span class=n>p</span> <span class=n>pgsockets</span>
</span></span><span class=line><span class=cl><span class=err>!</span><span class=n>pg_ctl</span> <span class=o>-</span><span class=n>D</span> <span class=n>pgtemp</span> <span class=o>-</span><span class=n>l</span> <span class=n>pg</span><span class=o>.</span><span class=n>log</span> <span class=n>start</span>
</span></span></code></pre></div><pre><code>waiting for server to start.... done
server started
</code></pre><p>Now we have a postgres on <code>127.0.0.1:5433</code>! Let&rsquo;s attach DuckDB to it so we can easily put the data in there. We will create an unlogged table that doesn&rsquo;t generate transaction logs, since they&rsquo;re not useful for this experiment. It should make it a bit faster to insert data into it. It also means that this table would essentially be lost if our postgres crashed, so think carefully before doing this on something important.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=o>%%</span><span class=k>sql</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>ATTACH</span><span class=w> </span><span class=s1>&#39;dbname=postgres user=postgres host=127.0.0.1 port=5433&#39;</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>pgtemp</span><span class=w> </span><span class=p>(</span><span class=k>TYPE</span><span class=w> </span><span class=n>postgres</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>CREATE</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=n>pgtemp</span><span class=p>.</span><span class=n>arrivals</span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>recordedAtTime</span><span class=w> </span><span class=k>TIMESTAMP</span><span class=w> </span><span class=k>WITH</span><span class=w> </span><span class=n>TIME</span><span class=w> </span><span class=k>ZONE</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>lineRef</span><span class=w> </span><span class=nb>VARCHAR</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>directionRef</span><span class=w> </span><span class=nb>VARCHAR</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>operatingDate</span><span class=w> </span><span class=nb>DATE</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>vehicleMode</span><span class=w> </span><span class=nb>VARCHAR</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>extraJourney</span><span class=w> </span><span class=nb>BOOLEAN</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>journeyCancellation</span><span class=w> </span><span class=nb>BOOLEAN</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>stopPointRef</span><span class=w> </span><span class=nb>VARCHAR</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>sequenceNr</span><span class=w> </span><span class=nb>BIGINT</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>stopPointName</span><span class=w> </span><span class=nb>VARCHAR</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>originName</span><span class=w> </span><span class=nb>VARCHAR</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>destinationName</span><span class=w> </span><span class=nb>VARCHAR</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>extraCall</span><span class=w> </span><span class=nb>BOOLEAN</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>stopCancellation</span><span class=w> </span><span class=nb>BOOLEAN</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>estimated</span><span class=w> </span><span class=nb>BOOLEAN</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>aimedArrivalTime</span><span class=w> </span><span class=k>TIMESTAMP</span><span class=w> </span><span class=k>WITH</span><span class=w> </span><span class=n>TIME</span><span class=w> </span><span class=k>ZONE</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>arrivalTime</span><span class=w> </span><span class=k>TIMESTAMP</span><span class=w> </span><span class=k>WITH</span><span class=w> </span><span class=n>TIME</span><span class=w> </span><span class=k>ZONE</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>aimedDepartureTime</span><span class=w> </span><span class=k>TIMESTAMP</span><span class=w> </span><span class=k>WITH</span><span class=w> </span><span class=n>TIME</span><span class=w> </span><span class=k>ZONE</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>departureTime</span><span class=w> </span><span class=k>TIMESTAMP</span><span class=w> </span><span class=k>WITH</span><span class=w> </span><span class=n>TIME</span><span class=w> </span><span class=k>ZONE</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>datedServiceJourneyId</span><span class=w> </span><span class=nb>VARCHAR</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>dataSource</span><span class=w> </span><span class=nb>VARCHAR</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>dataSourceName</span><span class=w> </span><span class=nb>VARCHAR</span><span class=p>);</span><span class=w>
</span></span></span></code></pre></div><p><span style=none>Running query in 'duckdb'</span></p><p>Let&rsquo;s make it unlogged:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=o>%%</span><span class=k>sql</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>CALL</span><span class=w> </span><span class=n>postgres_execute</span><span class=p>(</span><span class=s1>&#39;pgtemp&#39;</span><span class=p>,</span><span class=w> </span><span class=s1>&#39;ALTER TABLE arrivals SET UNLOGGED;&#39;</span><span class=p>)</span><span class=w>
</span></span></span></code></pre></div><p><span style=none>Running query in 'duckdb'</span></p><table><thead><tr><th>Success</th></tr></thead><tbody></tbody></table><p>Since our table schemas match, we should be able to use DuckDB to bulkload this efficiently. Let&rsquo;s give it a go:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=o>%%</span><span class=k>sql</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>INSERT</span><span class=w> </span><span class=k>INTO</span><span class=w> </span><span class=n>pgtemp</span><span class=p>.</span><span class=n>arrivals</span><span class=w> </span><span class=k>BY</span><span class=w> </span><span class=n>NAME</span><span class=w> </span><span class=k>SELECT</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=k>FROM</span><span class=w> </span><span class=n>arrivals</span><span class=p>;</span><span class=w>
</span></span></span></code></pre></div><p><span style=none>Running query in 'duckdb'</span></p><table><thead><tr><th>Count</th></tr></thead><tbody><tr><td>85079666</td></tr></tbody></table><p>Okay, the first thing I want to know is the size of the database after doing this, let&rsquo;s check:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=err>!</span><span class=n>du</span> <span class=o>-</span><span class=n>hs</span> <span class=n>pgtemp</span>
</span></span></code></pre></div><pre><code>18G	pgtemp
</code></pre><p>This is not surprising to me, columnar storage formats are much easier to compress efficiently than row storage formats, like the one used by postgres. This should fit in memory for postgres, it has 24GB RAM for shared buffers (and a generous 8GB for sorting and things like that). Let&rsquo;s time some basic operations in DuckDB vs postgres. We will limit DuckDB to 16GB RAM, so my machine can have something left over for running&mldr; everything else.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># limits for DuckDB</span>
</span></span><span class=line><span class=cl><span class=o>%</span><span class=n>sql</span> <span class=nb>set</span> <span class=n>memory_limit</span> <span class=o>=</span> <span class=s1>&#39;16GB&#39;</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=o>%</span><span class=n>sql</span> <span class=nb>set</span> <span class=n>threads</span> <span class=o>=</span> <span class=mi>11</span><span class=p>;</span> <span class=o>--</span> <span class=n>CPU</span> <span class=n>has</span> <span class=mi>12</span> <span class=n>physical</span> <span class=n>cores</span><span class=p>,</span> <span class=n>Ryzen</span> <span class=mi>9</span> <span class=mi>5900</span><span class=n>X</span><span class=o>.</span>
</span></span><span class=line><span class=cl><span class=o>%</span><span class=n>time</span> <span class=n>db</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&#34;select dataSource, count(*) from arrivals group by dataSource&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>df</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=o>%</span><span class=n>time</span> <span class=n>db</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=s2>&#34;&#34;&#34;call postgres_query(&#39;pgtemp&#39;, &#39;select &#34;dataSource&#34;, count(*) from arrivals group by &#34;dataSource&#34;&#39;)&#34;&#34;&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>df</span><span class=p>()</span>
</span></span></code></pre></div><pre><code>CPU times: user 316 ms, sys: 11.3 ms, total: 327 ms
Wall time: 31.6 ms

CPU times: user 11.3 s, sys: 854 μs, total: 11.3 s
Wall time: 11.3 s
</code></pre><p>I discarded the result set output from this, keeping only the execution times. For this very simple example, DuckDB can do it in 31.6ms and postgres needs 11.3 seconds.</p><p>This is a very unfair comparison, though. In this particular instance, DuckDB looks only at 1 column, and it is probably dictionary-encoded and run length encoded, similarly to how Arrow and Parquet does it. You can read a bit more about that <a href=https://arrow.apache.org/blog/2019/09/05/faster-strings-cpp-parquet/>here</a> and <a href=https://wesmckinney.com/blog/python-parquet-multithreading/>here</a>. This kind of query and data distribution is essentially a best-case for columnar storage formats. An index would help postgres here, but it would likely be significantly bigger than the column DuckDB has stored, and therefore still slower.</p><p>It may be much more fair to try to do a <code>group by</code> on a column where such shortcuts aren&rsquo;t possible. Let&rsquo;s count registrations by hour of day, which forces both implementations to look at all values of the <code>recordedAtTime</code> column.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>q</span> <span class=o>=</span> <span class=s1>&#39;select count(*), extract(hour from &#34;recordedAtTime&#34;) as hour from arrivals group by 2&#39;</span>
</span></span><span class=line><span class=cl><span class=o>%</span><span class=n>time</span> <span class=n>db</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=n>q</span><span class=p>)</span><span class=o>.</span><span class=n>df</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=o>%</span><span class=n>time</span> <span class=n>db</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;call postgres_query(&#39;pgtemp&#39;, &#39;</span><span class=si>{</span><span class=n>q</span><span class=si>}</span><span class=s2>&#39;)&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>df</span><span class=p>()</span>
</span></span></code></pre></div><pre><code>CPU times: user 18 s, sys: 0 ns, total: 18 s
Wall time: 1.65 s

CPU times: user 5.97 s, sys: 0 ns, total: 5.97 s
Wall time: 5.97 s
</code></pre><p>This time, the difference is much less drastic. DuckDB needs 1.65s and postgres can do it in 6s. For this query, DuckDB needed to investigate every value in the column, there&rsquo;s much less work that it can simply skip. Looking at the CPU time information, it seems obvious that DuckDB is using much more CPU to do this calculation than postgres, due to parallelization.</p><p>Let&rsquo;s try one that is a little tougher still. Let&rsquo;s use a window function to calculate the time from arrival at one stop, to the next and calculate some nonsense statistics about it. This will force both databases to do a lot of work using several columns. We may be able to make useful indexes for postgres here, but we&rsquo;ll try without first (I am expecting postgres to summarily lose this one without an index).</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>q</span> <span class=o>=</span> <span class=s1>&#39;&#39;&#39;
</span></span></span><span class=line><span class=cl><span class=s1>with times as (
</span></span></span><span class=line><span class=cl><span class=s1>    select 
</span></span></span><span class=line><span class=cl><span class=s1>      extract(epoch from 
</span></span></span><span class=line><span class=cl><span class=s1>          lead(&#34;arrivalTime&#34;, 1) over (partition by &#34;datedServiceJourneyId&#34; order by &#34;sequenceNr&#34;) 
</span></span></span><span class=line><span class=cl><span class=s1>           - &#34;arrivalTime&#34;
</span></span></span><span class=line><span class=cl><span class=s1>      ) as timedelta
</span></span></span><span class=line><span class=cl><span class=s1>    from arrivals
</span></span></span><span class=line><span class=cl><span class=s1>)
</span></span></span><span class=line><span class=cl><span class=s1>select
</span></span></span><span class=line><span class=cl><span class=s1>    max(timedelta), min(timedelta), sum(timedelta) / count(*) -- avg in postgres and mean in duckdb
</span></span></span><span class=line><span class=cl><span class=s1>from times
</span></span></span><span class=line><span class=cl><span class=s1>&#39;&#39;&#39;</span>
</span></span><span class=line><span class=cl><span class=o>%</span><span class=n>time</span> <span class=n>db</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=n>q</span><span class=p>)</span><span class=o>.</span><span class=n>df</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=o>%</span><span class=n>time</span> <span class=n>db</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;call postgres_query(&#39;pgtemp&#39;, &#39;</span><span class=si>{</span><span class=n>q</span><span class=si>}</span><span class=s2>&#39;)&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>df</span><span class=p>()</span>
</span></span></code></pre></div><pre><code>CPU times: user 2min 40s, sys: 9.72 s, total: 2min 50s
Wall time: 15.7 s

CPU times: user 8min 15s, sys: 52.2 ms, total: 8min 15s
Wall time: 8min 15s
</code></pre><p>Wow, that&rsquo;s a big difference. DuckDB spent 15.7s and postgres spent 8 mins 15s. I am not sure why the difference is so big in this case. Even a table scan should be quite quick for postgres now, the data is certainly in RAM already. This difference is so large that I can&rsquo;t explain it without involving disk usage.</p><p>In this case, it would have been much faster to pull all the data out from postgres and into DuckDB and do the aggregation there. I&rsquo;m betting we can help postgres by making an index that matches the partition of the window function. Let&rsquo;s do that.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>index</span> <span class=o>=</span> <span class=s1>&#39;create index on arrivals(&#34;datedServiceJourneyId&#34;, &#34;sequenceNr&#34;);&#39;</span>
</span></span><span class=line><span class=cl><span class=o>%</span><span class=n>time</span> <span class=n>db</span><span class=o>.</span><span class=n>execute</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;call postgres_execute(&#39;pgtemp&#39;, &#39;</span><span class=si>{</span><span class=n>index</span><span class=si>}</span><span class=s2>&#39;);&#34;</span><span class=p>)</span>
</span></span></code></pre></div><pre><code>CPU times: user 3min 3s, sys: 954 ms, total: 3min 4s
Wall time: 3min 3s
</code></pre><p>3 minutes, less time than running the query originally. Let&rsquo;s try the query one more time:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=o>%</span><span class=n>time</span> <span class=n>db</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;call postgres_query(&#39;pgtemp&#39;, &#39;</span><span class=si>{</span><span class=n>q</span><span class=si>}</span><span class=s2>&#39;)&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>df</span><span class=p>()</span>
</span></span></code></pre></div><pre><code>CPU times: user 8min 16s, sys: 432 ms, total: 8min 17s
Wall time: 8min 16s
</code></pre><p>Right, the index was not useful. Perhaps because the table fits in memory anyway. I made sure to <code>ANALYZE;</code> and try again, just in case. On disk, this index is larger than the entire DuckDB file, creating it increased the size of the <code>pgtemp</code> postgres cluster to 25GB:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=err>!</span><span class=n>du</span> <span class=o>-</span><span class=n>hs</span> <span class=n>pgtemp</span>
</span></span></code></pre></div><pre><code>25G	pgtemp
</code></pre><p>One variation that we haven&rsquo;t tried yet, is to just run the query in DuckDB, but against the postgres table (meaning DuckDB will have to delegate some work to postgres, or copy out all the data).</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=o>%</span><span class=n>time</span> <span class=n>db</span><span class=o>.</span><span class=n>sql</span><span class=p>(</span><span class=n>q</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=s2>&#34;arrivals&#34;</span><span class=p>,</span> <span class=s2>&#34;pgtemp.arrivals&#34;</span><span class=p>))</span><span class=o>.</span><span class=n>df</span><span class=p>()</span>
</span></span></code></pre></div><pre><code>CPU times: user 3min, sys: 13.6 s, total: 3min 14s
Wall time: 25.7 s
</code></pre><p>Right, that&rsquo;s very interesting, that&rsquo;s 25.7s compared to the 8 minutes of running purely in postgres or the 13.4s of running purely against DuckDB. This would create load and IO on the postgres database server, naturally, but maybe that&rsquo;s a good way to offload the heavy computational work onto the applicationserver?</p><p>I&rsquo;m going to go look some more into what&rsquo;s happening in postgres here, it does not make sense to me that it can take 8 minutes to run this query if everything&rsquo;s in memory. I&rsquo;ll head over to <code>psql</code> and check out what <code>explain (analyze on, buffers on)</code> tells me.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=n>postgres</span><span class=o>=#</span><span class=w> </span><span class=k>explain</span><span class=w> </span><span class=p>(</span><span class=k>analyze</span><span class=w> </span><span class=k>on</span><span class=p>,</span><span class=w> </span><span class=n>buffers</span><span class=w> </span><span class=k>on</span><span class=p>)</span><span class=w> </span><span class=k>with</span><span class=w> </span><span class=n>times</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>select</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=k>extract</span><span class=p>(</span><span class=n>epoch</span><span class=w> </span><span class=k>from</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=n>lead</span><span class=p>(</span><span class=s2>&#34;arrivalTime&#34;</span><span class=p>,</span><span class=w> </span><span class=mi>1</span><span class=p>)</span><span class=w> </span><span class=n>over</span><span class=w> </span><span class=p>(</span><span class=n>partition</span><span class=w> </span><span class=k>by</span><span class=w> </span><span class=s2>&#34;datedServiceJourneyId&#34;</span><span class=w> </span><span class=k>order</span><span class=w> </span><span class=k>by</span><span class=w> </span><span class=s2>&#34;sequenceNr&#34;</span><span class=p>)</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w>           </span><span class=o>-</span><span class=w> </span><span class=s2>&#34;arrivalTime&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=p>)</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=n>timedelta</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>from</span><span class=w> </span><span class=n>arrivals</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>select</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>max</span><span class=p>(</span><span class=n>timedelta</span><span class=p>),</span><span class=w> </span><span class=k>min</span><span class=p>(</span><span class=n>timedelta</span><span class=p>),</span><span class=w> </span><span class=k>sum</span><span class=p>(</span><span class=n>timedelta</span><span class=p>)</span><span class=w> </span><span class=o>/</span><span class=w> </span><span class=k>count</span><span class=p>(</span><span class=o>*</span><span class=p>)</span><span class=w> </span><span class=c1>-- avg in postgres and mean in duckdb
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>from</span><span class=w> </span><span class=n>times</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                                                                  </span><span class=n>QUERY</span><span class=w> </span><span class=n>PLAN</span><span class=w>                                                                   
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>-----------------------------------------------------------------------------------------------------------------------------------------------
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=w> </span><span class=k>Aggregate</span><span class=w>  </span><span class=p>(</span><span class=n>cost</span><span class=o>=</span><span class=mi>18207075</span><span class=p>.</span><span class=mi>69</span><span class=p>..</span><span class=mi>18207075</span><span class=p>.</span><span class=mi>71</span><span class=w> </span><span class=k>rows</span><span class=o>=</span><span class=mi>1</span><span class=w> </span><span class=n>width</span><span class=o>=</span><span class=mi>96</span><span class=p>)</span><span class=w> </span><span class=p>(</span><span class=n>actual</span><span class=w> </span><span class=n>time</span><span class=o>=</span><span class=mi>506560</span><span class=p>.</span><span class=mi>516</span><span class=p>..</span><span class=mi>506560</span><span class=p>.</span><span class=mi>517</span><span class=w> </span><span class=k>rows</span><span class=o>=</span><span class=mi>1</span><span class=w> </span><span class=n>loops</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>   </span><span class=n>Buffers</span><span class=p>:</span><span class=w> </span><span class=n>shared</span><span class=w> </span><span class=n>hit</span><span class=o>=</span><span class=mi>2729</span><span class=w> </span><span class=k>read</span><span class=o>=</span><span class=mi>2314831</span><span class=p>,</span><span class=w> </span><span class=n>temp</span><span class=w> </span><span class=k>read</span><span class=o>=</span><span class=mi>813011</span><span class=w> </span><span class=n>written</span><span class=o>=</span><span class=mi>813012</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>   </span><span class=o>-&gt;</span><span class=w>  </span><span class=n>WindowAgg</span><span class=w>  </span><span class=p>(</span><span class=n>cost</span><span class=o>=</span><span class=mi>14377525</span><span class=p>.</span><span class=mi>67</span><span class=p>..</span><span class=mi>16505053</span><span class=p>.</span><span class=mi>45</span><span class=w> </span><span class=k>rows</span><span class=o>=</span><span class=mi>85101112</span><span class=w> </span><span class=n>width</span><span class=o>=</span><span class=mi>90</span><span class=p>)</span><span class=w> </span><span class=p>(</span><span class=n>actual</span><span class=w> </span><span class=n>time</span><span class=o>=</span><span class=mi>467725</span><span class=p>.</span><span class=mi>139</span><span class=p>..</span><span class=mi>501383</span><span class=p>.</span><span class=mi>481</span><span class=w> </span><span class=k>rows</span><span class=o>=</span><span class=mi>85079666</span><span class=w> </span><span class=n>loops</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>         </span><span class=n>Buffers</span><span class=p>:</span><span class=w> </span><span class=n>shared</span><span class=w> </span><span class=n>hit</span><span class=o>=</span><span class=mi>2729</span><span class=w> </span><span class=k>read</span><span class=o>=</span><span class=mi>2314831</span><span class=p>,</span><span class=w> </span><span class=n>temp</span><span class=w> </span><span class=k>read</span><span class=o>=</span><span class=mi>813011</span><span class=w> </span><span class=n>written</span><span class=o>=</span><span class=mi>813012</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>         </span><span class=o>-&gt;</span><span class=w>  </span><span class=n>Sort</span><span class=w>  </span><span class=p>(</span><span class=n>cost</span><span class=o>=</span><span class=mi>14377525</span><span class=p>.</span><span class=mi>65</span><span class=p>..</span><span class=mi>14590278</span><span class=p>.</span><span class=mi>43</span><span class=w> </span><span class=k>rows</span><span class=o>=</span><span class=mi>85101112</span><span class=w> </span><span class=n>width</span><span class=o>=</span><span class=mi>66</span><span class=p>)</span><span class=w> </span><span class=p>(</span><span class=n>actual</span><span class=w> </span><span class=n>time</span><span class=o>=</span><span class=mi>467725</span><span class=p>.</span><span class=mi>100</span><span class=p>..</span><span class=mi>474901</span><span class=p>.</span><span class=mi>976</span><span class=w> </span><span class=k>rows</span><span class=o>=</span><span class=mi>85079666</span><span class=w> </span><span class=n>loops</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>               </span><span class=n>Sort</span><span class=w> </span><span class=k>Key</span><span class=p>:</span><span class=w> </span><span class=n>arrivals</span><span class=p>.</span><span class=s2>&#34;datedServiceJourneyId&#34;</span><span class=p>,</span><span class=w> </span><span class=n>arrivals</span><span class=p>.</span><span class=s2>&#34;sequenceNr&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>               </span><span class=n>Sort</span><span class=w> </span><span class=k>Method</span><span class=p>:</span><span class=w> </span><span class=k>external</span><span class=w> </span><span class=n>merge</span><span class=w>  </span><span class=n>Disk</span><span class=p>:</span><span class=w> </span><span class=mi>6504088</span><span class=n>kB</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>               </span><span class=n>Buffers</span><span class=p>:</span><span class=w> </span><span class=n>shared</span><span class=w> </span><span class=n>hit</span><span class=o>=</span><span class=mi>2729</span><span class=w> </span><span class=k>read</span><span class=o>=</span><span class=mi>2314831</span><span class=p>,</span><span class=w> </span><span class=n>temp</span><span class=w> </span><span class=k>read</span><span class=o>=</span><span class=mi>813011</span><span class=w> </span><span class=n>written</span><span class=o>=</span><span class=mi>813012</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>               </span><span class=o>-&gt;</span><span class=w>  </span><span class=n>Seq</span><span class=w> </span><span class=n>Scan</span><span class=w> </span><span class=k>on</span><span class=w> </span><span class=n>arrivals</span><span class=w>  </span><span class=p>(</span><span class=n>cost</span><span class=o>=</span><span class=mi>0</span><span class=p>.</span><span class=mi>00</span><span class=p>..</span><span class=mi>3168571</span><span class=p>.</span><span class=mi>12</span><span class=w> </span><span class=k>rows</span><span class=o>=</span><span class=mi>85101112</span><span class=w> </span><span class=n>width</span><span class=o>=</span><span class=mi>66</span><span class=p>)</span><span class=w> </span><span class=p>(</span><span class=n>actual</span><span class=w> </span><span class=n>time</span><span class=o>=</span><span class=mi>199</span><span class=p>.</span><span class=mi>763</span><span class=p>..</span><span class=mi>17347</span><span class=p>.</span><span class=mi>756</span><span class=w> </span><span class=k>rows</span><span class=o>=</span><span class=mi>85079666</span><span class=w> </span><span class=n>loops</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                     </span><span class=n>Buffers</span><span class=p>:</span><span class=w> </span><span class=n>shared</span><span class=w> </span><span class=n>hit</span><span class=o>=</span><span class=mi>2729</span><span class=w> </span><span class=k>read</span><span class=o>=</span><span class=mi>2314831</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w> </span><span class=n>Planning</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>   </span><span class=n>Buffers</span><span class=p>:</span><span class=w> </span><span class=n>shared</span><span class=w> </span><span class=n>hit</span><span class=o>=</span><span class=mi>22</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w> </span><span class=n>Planning</span><span class=w> </span><span class=n>Time</span><span class=p>:</span><span class=w> </span><span class=mi>0</span><span class=p>.</span><span class=mi>371</span><span class=w> </span><span class=n>ms</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w> </span><span class=n>JIT</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>   </span><span class=n>Functions</span><span class=p>:</span><span class=w> </span><span class=mi>11</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>   </span><span class=k>Options</span><span class=p>:</span><span class=w> </span><span class=n>Inlining</span><span class=w> </span><span class=k>true</span><span class=p>,</span><span class=w> </span><span class=n>Optimization</span><span class=w> </span><span class=k>true</span><span class=p>,</span><span class=w> </span><span class=n>Expressions</span><span class=w> </span><span class=k>true</span><span class=p>,</span><span class=w> </span><span class=n>Deforming</span><span class=w> </span><span class=k>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>   </span><span class=n>Timing</span><span class=p>:</span><span class=w> </span><span class=n>Generation</span><span class=w> </span><span class=mi>0</span><span class=p>.</span><span class=mi>608</span><span class=w> </span><span class=n>ms</span><span class=w> </span><span class=p>(</span><span class=n>Deform</span><span class=w> </span><span class=mi>0</span><span class=p>.</span><span class=mi>255</span><span class=w> </span><span class=n>ms</span><span class=p>),</span><span class=w> </span><span class=n>Inlining</span><span class=w> </span><span class=mi>64</span><span class=p>.</span><span class=mi>518</span><span class=w> </span><span class=n>ms</span><span class=p>,</span><span class=w> </span><span class=n>Optimization</span><span class=w> </span><span class=mi>68</span><span class=p>.</span><span class=mi>888</span><span class=w> </span><span class=n>ms</span><span class=p>,</span><span class=w> </span><span class=n>Emission</span><span class=w> </span><span class=mi>66</span><span class=p>.</span><span class=mi>374</span><span class=w> </span><span class=n>ms</span><span class=p>,</span><span class=w> </span><span class=n>Total</span><span class=w> </span><span class=mi>200</span><span class=p>.</span><span class=mi>389</span><span class=w> </span><span class=n>ms</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w> </span><span class=n>Execution</span><span class=w> </span><span class=n>Time</span><span class=p>:</span><span class=w> </span><span class=mi>507455</span><span class=p>.</span><span class=mi>248</span><span class=w> </span><span class=n>ms</span><span class=w>
</span></span></span></code></pre></div><p>Aha, so it&rsquo;s sorting on disk. That means it may help to increase <code>work_mem</code>. I&rsquo;ll try to double it to 16GB with <code>set work_mem='16GB';</code> (and close some applications on this machine). I will also create an index that includes all the 3 columns this query uses, to try to get an <code>Index Only Scan</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=n>postgres</span><span class=o>=#</span><span class=w> </span><span class=k>create</span><span class=w> </span><span class=k>index</span><span class=w> </span><span class=k>on</span><span class=w> </span><span class=n>arrivals</span><span class=p>(</span><span class=s2>&#34;datedServiceJourneyId&#34;</span><span class=p>,</span><span class=w> </span><span class=s2>&#34;sequenceNr&#34;</span><span class=p>,</span><span class=w> </span><span class=s2>&#34;arrivalTime&#34;</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>CREATE</span><span class=w> </span><span class=k>INDEX</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>postgres</span><span class=o>=#</span><span class=w> </span><span class=k>explain</span><span class=w> </span><span class=p>(</span><span class=k>analyze</span><span class=w> </span><span class=k>on</span><span class=p>,</span><span class=w> </span><span class=n>buffers</span><span class=w> </span><span class=k>on</span><span class=p>)</span><span class=w> </span><span class=k>with</span><span class=w> </span><span class=n>times</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>select</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=k>extract</span><span class=p>(</span><span class=n>epoch</span><span class=w> </span><span class=k>from</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=n>lead</span><span class=p>(</span><span class=s2>&#34;arrivalTime&#34;</span><span class=p>,</span><span class=w> </span><span class=mi>1</span><span class=p>)</span><span class=w> </span><span class=n>over</span><span class=w> </span><span class=p>(</span><span class=n>partition</span><span class=w> </span><span class=k>by</span><span class=w> </span><span class=s2>&#34;datedServiceJourneyId&#34;</span><span class=w> </span><span class=k>order</span><span class=w> </span><span class=k>by</span><span class=w> </span><span class=s2>&#34;sequenceNr&#34;</span><span class=p>)</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w>           </span><span class=o>-</span><span class=w> </span><span class=s2>&#34;arrivalTime&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=p>)</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=n>timedelta</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>from</span><span class=w> </span><span class=n>arrivals</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>select</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>max</span><span class=p>(</span><span class=n>timedelta</span><span class=p>),</span><span class=w> </span><span class=k>min</span><span class=p>(</span><span class=n>timedelta</span><span class=p>),</span><span class=w> </span><span class=k>sum</span><span class=p>(</span><span class=n>timedelta</span><span class=p>)</span><span class=w> </span><span class=o>/</span><span class=w> </span><span class=k>count</span><span class=p>(</span><span class=o>*</span><span class=p>)</span><span class=w> </span><span class=c1>-- avg in postgres and mean in duckdb
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>from</span><span class=w> </span><span class=n>times</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                                                                                               </span><span class=n>QUERY</span><span class=w> </span><span class=n>PLAN</span><span class=w>                                                                                                    
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=w> </span><span class=k>Aggregate</span><span class=w>  </span><span class=p>(</span><span class=n>cost</span><span class=o>=</span><span class=mi>8735893</span><span class=p>.</span><span class=mi>91</span><span class=p>..</span><span class=mi>8735893</span><span class=p>.</span><span class=mi>93</span><span class=w> </span><span class=k>rows</span><span class=o>=</span><span class=mi>1</span><span class=w> </span><span class=n>width</span><span class=o>=</span><span class=mi>96</span><span class=p>)</span><span class=w> </span><span class=p>(</span><span class=n>actual</span><span class=w> </span><span class=n>time</span><span class=o>=</span><span class=mi>46947</span><span class=p>.</span><span class=mi>869</span><span class=p>..</span><span class=mi>46947</span><span class=p>.</span><span class=mi>870</span><span class=w> </span><span class=k>rows</span><span class=o>=</span><span class=mi>1</span><span class=w> </span><span class=n>loops</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>   </span><span class=n>Buffers</span><span class=p>:</span><span class=w> </span><span class=n>shared</span><span class=w> </span><span class=n>hit</span><span class=o>=</span><span class=mi>51347699</span><span class=w> </span><span class=k>read</span><span class=o>=</span><span class=mi>947841</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>   </span><span class=o>-&gt;</span><span class=w>  </span><span class=n>WindowAgg</span><span class=w>  </span><span class=p>(</span><span class=n>cost</span><span class=o>=</span><span class=mi>0</span><span class=p>.</span><span class=mi>77</span><span class=p>..</span><span class=mi>7034300</span><span class=p>.</span><span class=mi>63</span><span class=w> </span><span class=k>rows</span><span class=o>=</span><span class=mi>85079664</span><span class=w> </span><span class=n>width</span><span class=o>=</span><span class=mi>90</span><span class=p>)</span><span class=w> </span><span class=p>(</span><span class=n>actual</span><span class=w> </span><span class=n>time</span><span class=o>=</span><span class=mi>61</span><span class=p>.</span><span class=mi>489</span><span class=p>..</span><span class=mi>41859</span><span class=p>.</span><span class=mi>920</span><span class=w> </span><span class=k>rows</span><span class=o>=</span><span class=mi>85079666</span><span class=w> </span><span class=n>loops</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>         </span><span class=n>Buffers</span><span class=p>:</span><span class=w> </span><span class=n>shared</span><span class=w> </span><span class=n>hit</span><span class=o>=</span><span class=mi>51347699</span><span class=w> </span><span class=k>read</span><span class=o>=</span><span class=mi>947841</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>         </span><span class=o>-&gt;</span><span class=w>  </span><span class=k>Index</span><span class=w> </span><span class=k>Only</span><span class=w> </span><span class=n>Scan</span><span class=w> </span><span class=k>using</span><span class=w> </span><span class=s2>&#34;arrivals_datedServiceJourneyId_sequenceNr_arrivalTime_idx&#34;</span><span class=w> </span><span class=k>on</span><span class=w> </span><span class=n>arrivals</span><span class=w>  </span><span class=p>(</span><span class=n>cost</span><span class=o>=</span><span class=mi>0</span><span class=p>.</span><span class=mi>69</span><span class=p>..</span><span class=mi>5120008</span><span class=p>.</span><span class=mi>19</span><span class=w> </span><span class=k>rows</span><span class=o>=</span><span class=mi>85079664</span><span class=w> </span><span class=n>width</span><span class=o>=</span><span class=mi>66</span><span class=p>)</span><span class=w> </span><span class=p>(</span><span class=n>actual</span><span class=w> </span><span class=n>time</span><span class=o>=</span><span class=mi>61</span><span class=p>.</span><span class=mi>471</span><span class=p>..</span><span class=mi>12268</span><span class=p>.</span><span class=mi>748</span><span class=w> </span><span class=k>rows</span><span class=o>=</span><span class=mi>85079666</span><span class=w> </span><span class=n>loops</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>               </span><span class=n>Heap</span><span class=w> </span><span class=n>Fetches</span><span class=p>:</span><span class=w> </span><span class=mi>0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>               </span><span class=n>Buffers</span><span class=p>:</span><span class=w> </span><span class=n>shared</span><span class=w> </span><span class=n>hit</span><span class=o>=</span><span class=mi>51347699</span><span class=w> </span><span class=k>read</span><span class=o>=</span><span class=mi>947841</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w> </span><span class=n>Planning</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>   </span><span class=n>Buffers</span><span class=p>:</span><span class=w> </span><span class=n>shared</span><span class=w> </span><span class=n>hit</span><span class=o>=</span><span class=mi>22</span><span class=w> </span><span class=k>read</span><span class=o>=</span><span class=mi>1</span><span class=w> </span><span class=n>dirtied</span><span class=o>=</span><span class=mi>2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w> </span><span class=n>Planning</span><span class=w> </span><span class=n>Time</span><span class=p>:</span><span class=w> </span><span class=mi>14</span><span class=p>.</span><span class=mi>759</span><span class=w> </span><span class=n>ms</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w> </span><span class=n>JIT</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>   </span><span class=n>Functions</span><span class=p>:</span><span class=w> </span><span class=mi>10</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>   </span><span class=k>Options</span><span class=p>:</span><span class=w> </span><span class=n>Inlining</span><span class=w> </span><span class=k>true</span><span class=p>,</span><span class=w> </span><span class=n>Optimization</span><span class=w> </span><span class=k>true</span><span class=p>,</span><span class=w> </span><span class=n>Expressions</span><span class=w> </span><span class=k>true</span><span class=p>,</span><span class=w> </span><span class=n>Deforming</span><span class=w> </span><span class=k>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>   </span><span class=n>Timing</span><span class=p>:</span><span class=w> </span><span class=n>Generation</span><span class=w> </span><span class=mi>0</span><span class=p>.</span><span class=mi>499</span><span class=w> </span><span class=n>ms</span><span class=w> </span><span class=p>(</span><span class=n>Deform</span><span class=w> </span><span class=mi>0</span><span class=p>.</span><span class=mi>116</span><span class=w> </span><span class=n>ms</span><span class=p>),</span><span class=w> </span><span class=n>Inlining</span><span class=w> </span><span class=mi>11</span><span class=p>.</span><span class=mi>793</span><span class=w> </span><span class=n>ms</span><span class=p>,</span><span class=w> </span><span class=n>Optimization</span><span class=w> </span><span class=mi>28</span><span class=p>.</span><span class=mi>170</span><span class=w> </span><span class=n>ms</span><span class=p>,</span><span class=w> </span><span class=n>Emission</span><span class=w> </span><span class=mi>21</span><span class=p>.</span><span class=mi>494</span><span class=w> </span><span class=n>ms</span><span class=p>,</span><span class=w> </span><span class=n>Total</span><span class=w> </span><span class=mi>61</span><span class=p>.</span><span class=mi>955</span><span class=w> </span><span class=n>ms</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w> </span><span class=n>Execution</span><span class=w> </span><span class=n>Time</span><span class=p>:</span><span class=w> </span><span class=mi>46950</span><span class=p>.</span><span class=mi>351</span><span class=w> </span><span class=n>ms</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>(</span><span class=mi>15</span><span class=w> </span><span class=k>rows</span><span class=p>)</span><span class=w>
</span></span></span></code></pre></div><p>That&rsquo;s more like it. So if we back the query with an appropriate index, postgres can run this query in 47s, which is quite close to DuckDB, considering that it doesn&rsquo;t use all my cores. This index is 7504MB, though, and took some minutes to create. In other words, I need to know that I must back this query with an index to get good performance. If this was a database server with some transactional workload, it could have consequences to run the query without the index. We&rsquo;re also relying on the index being in memory to get good performance here.</p><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>Here&rsquo;s the short summary:</p><ul><li>DuckDB can&rsquo;t do concurrent write transactions. postgres is great for that!</li><li>postgres can parallelize queries, but DuckDB does this much more aggressively.</li><li>DuckDB is more forgiving on analytical queries if you haven&rsquo;t set up the correct indexes.</li><li>DuckDB is likely to be much faster for analytical queries on big data sets.</li><li>DuckDB stores data much more compactly.</li><li>postgres is great for sharing compute resources fairly between many concurrent users.</li><li>But they seem to work great together too!</li></ul><p>I&rsquo;m going to clean up my mess here and call it a day. I do think it&rsquo;s probably true that postgres can do almost everything that DuckDB can do. But I can definitely see a case for having both, they complement each others capabilities really well.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=err>!</span><span class=n>pg_ctl</span> <span class=n>stop</span> <span class=o>-</span><span class=n>D</span> <span class=n>pgtemp</span>
</span></span><span class=line><span class=cl><span class=err>!</span><span class=n>rm</span> <span class=o>-</span><span class=n>rf</span> <span class=n>pgtemp</span>
</span></span></code></pre></div><pre><code>waiting for server to shut down...... done
server stopped
</code></pre><p>Thanks for reading!</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://kaveland.no/tags/data/>Data</a></li><li><a href=https://kaveland.no/tags/duckdb/>Duckdb</a></li><li><a href=https://kaveland.no/tags/postgres/>Postgres</a></li><li><a href=https://kaveland.no/tags/sql/>Sql</a></li></ul><nav class=paginav><a class=prev href=https://kaveland.no/posts/2025-03-10-mutual-recursion-for-fun-and-profit/><span class=title>« Prev</span><br><span>Constraint propagation: Mutual recursion for fun and profit</span>
</a><a class=next href=https://kaveland.no/posts/2025-01-26-points-of-data/><span class=title>Next »</span><br><span>🎶 These points of data make a beautiful line 🎶</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Why would I use DuckDB for that? on x" href="https://x.com/intent/tweet/?text=Why%20would%20I%20use%20DuckDB%20for%20that%3f&amp;url=https%3a%2f%2fkaveland.no%2fposts%2f2025-03-02-can-i-just-use-postgres%2f&amp;hashtags=data%2cduckdb%2cpostgres%2csql"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Why would I use DuckDB for that? on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fkaveland.no%2fposts%2f2025-03-02-can-i-just-use-postgres%2f&amp;title=Why%20would%20I%20use%20DuckDB%20for%20that%3f&amp;summary=Why%20would%20I%20use%20DuckDB%20for%20that%3f&amp;source=https%3a%2f%2fkaveland.no%2fposts%2f2025-03-02-can-i-just-use-postgres%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Why would I use DuckDB for that? on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fkaveland.no%2fposts%2f2025-03-02-can-i-just-use-postgres%2f&title=Why%20would%20I%20use%20DuckDB%20for%20that%3f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Why would I use DuckDB for that? on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fkaveland.no%2fposts%2f2025-03-02-can-i-just-use-postgres%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Why would I use DuckDB for that? on whatsapp" href="https://api.whatsapp.com/send?text=Why%20would%20I%20use%20DuckDB%20for%20that%3f%20-%20https%3a%2f%2fkaveland.no%2fposts%2f2025-03-02-can-i-just-use-postgres%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Why would I use DuckDB for that? on telegram" href="https://telegram.me/share/url?text=Why%20would%20I%20use%20DuckDB%20for%20that%3f&amp;url=https%3a%2f%2fkaveland.no%2fposts%2f2025-03-02-can-i-just-use-postgres%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Why would I use DuckDB for that? on ycombinator" href="https://news.ycombinator.com/submitlink?t=Why%20would%20I%20use%20DuckDB%20for%20that%3f&u=https%3a%2f%2fkaveland.no%2fposts%2f2025-03-02-can-i-just-use-postgres%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://kaveland.no/>Robin's blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>