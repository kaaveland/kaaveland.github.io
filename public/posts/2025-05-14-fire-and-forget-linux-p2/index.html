<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>No-ops linux part 2: Hosting a simple container on a lean mean systemd machine | Robin's blog</title>
<meta name=keywords content="cloud,linux,ops,cdn,duckdb,caddy,ansible"><meta name=description content="This post is part of the series on no-ops linux deployment. The previous post covered local development of linux server configuration and essential configuration. This installment covers a janky podman installation and configures a reverse proxy to send traffic to a simple container deployment. The final post covers a more challenging deployment with jobs and rolling restarts, and discusses the strengths and weaknesses of this approach to hosting.
At the completion of the previous post, we had automatic installation of a functional Ubuntu server with the bare essentials installed. We did this by writing a base-install ansible role. There&rsquo;s still a missing ingredient before we can start deploying containers, though!"><meta name=author content="Robin Kåveland"><link rel=canonical href=https://kaveland.no/posts/2025-05-14-fire-and-forget-linux-p2/><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=https://kaveland.no/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://kaveland.no/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://kaveland.no/favicon-32x32.png><link rel=apple-touch-icon href=https://kaveland.no/apple-touch-icon.png><link rel=mask-icon href=https://kaveland.no/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://kaveland.no/posts/2025-05-14-fire-and-forget-linux-p2/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script defer data-domain=kaveland.no src=https://plausible.io/js/script.js></script><meta property="og:title" content="No-ops linux part 2: Hosting a simple container on a lean mean systemd machine"><meta property="og:description" content="This post is part of the series on no-ops linux deployment. The previous post covered local development of linux server configuration and essential configuration. This installment covers a janky podman installation and configures a reverse proxy to send traffic to a simple container deployment. The final post covers a more challenging deployment with jobs and rolling restarts, and discusses the strengths and weaknesses of this approach to hosting.
At the completion of the previous post, we had automatic installation of a functional Ubuntu server with the bare essentials installed. We did this by writing a base-install ansible role. There&rsquo;s still a missing ingredient before we can start deploying containers, though!"><meta property="og:type" content="article"><meta property="og:url" content="https://kaveland.no/posts/2025-05-14-fire-and-forget-linux-p2/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-05-14T00:00:00+00:00"><meta property="article:modified_time" content="2025-05-14T00:00:00+00:00"><meta property="og:site_name" content="Robin's blog"><meta name=twitter:card content="summary"><meta name=twitter:title content="No-ops linux part 2: Hosting a simple container on a lean mean systemd machine"><meta name=twitter:description content="This post is part of the series on no-ops linux deployment. The previous post covered local development of linux server configuration and essential configuration. This installment covers a janky podman installation and configures a reverse proxy to send traffic to a simple container deployment. The final post covers a more challenging deployment with jobs and rolling restarts, and discusses the strengths and weaknesses of this approach to hosting.
At the completion of the previous post, we had automatic installation of a functional Ubuntu server with the bare essentials installed. We did this by writing a base-install ansible role. There&rsquo;s still a missing ingredient before we can start deploying containers, though!"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://kaveland.no/posts/"},{"@type":"ListItem","position":2,"name":"No-ops linux part 2: Hosting a simple container on a lean mean systemd machine","item":"https://kaveland.no/posts/2025-05-14-fire-and-forget-linux-p2/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"No-ops linux part 2: Hosting a simple container on a lean mean systemd machine","name":"No-ops linux part 2: Hosting a simple container on a lean mean systemd machine","description":"This post is part of the series on no-ops linux deployment. The previous post covered local development of linux server configuration and essential configuration. This installment covers a janky podman installation and configures a reverse proxy to send traffic to a simple container deployment. The final post covers a more challenging deployment with jobs and rolling restarts, and discusses the strengths and weaknesses of this approach to hosting.\nAt the completion of the previous post, we had automatic installation of a functional Ubuntu server with the bare essentials installed. We did this by writing a base-install ansible role. There\u0026rsquo;s still a missing ingredient before we can start deploying containers, though!\n","keywords":["cloud","linux","ops","cdn","duckdb","caddy","ansible"],"articleBody":"This post is part of the series on no-ops linux deployment. The previous post covered local development of linux server configuration and essential configuration. This installment covers a janky podman installation and configures a reverse proxy to send traffic to a simple container deployment. The final post covers a more challenging deployment with jobs and rolling restarts, and discusses the strengths and weaknesses of this approach to hosting.\nAt the completion of the previous post, we had automatic installation of a functional Ubuntu server with the bare essentials installed. We did this by writing a base-install ansible role. There’s still a missing ingredient before we can start deploying containers, though!\nIt’s time to introduce ✨podman✨ podman is a tool for running containers. It’s CLI-compatible with docker, and has deep and useful integrations with systemd, the init on most modern Linux installations. I want to use systemd to manage my containers for me with podman systemd units. This has nice features like auto-updating images, takes care of getting the log where I can read it, can restart failed containers and so on. podman will also run docker-compose files for you.\nUbuntu 24.04 (codename Noble) ships with podman 4.9, which is a year old and missing some features I want:\nsystemd template support for quadlet files (we’ll get to this, don’t worry) Some limited support for using k8s YAML with podman (I know I said I wanted to avoid YAML, but this may come in handy) Many quality of life improvements to quadlets Ubuntu 25.04 (codename Plucky) has podman 5.4, which has everything I want, but 25.04 isn’t Long Term Support and not available at all cloud providers.\nIt’s a little dirty, but what I’ll do is to add the podman package from 25.04. This is not without risk, it could break things in the future. We’ll have to hope that grizzled ops veterans avert their eyes and the gods of fortune and luck are with us.\nWe’ll add the 25.04 sources to apt, using the new-fangled and cool .sources format. I need to use a template for this because my laptop is running on arm, but I’m probably going to end up provisioning to an x86 machine, and there are different package URIs for those. Let’s create roles/podman/templates/plucky.sources.j2 with this content:\nTypes: deb {% if ansible_architecture == 'aarch64' or ansible_architecture == 'arm64' %} URIs: http://ports.ubuntu.com/ubuntu-ports {% else %} URIs: http://archive.ubuntu.com/ubuntu {% endif %} Suites: plucky plucky-updates Components: main universe restricted Signed-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg The {% if ... } is jinja2-syntax, and ansible knows what kind of architecture the machine has. But just adding this, we risk upgrading tons of packages to the 25.04 distribution, and we don’t want that. We can limit the blast radius by setting up a .pref file that pins only the packages we think we need to 25.04. I found a list at this issue that looks good. We’ll add this to roles/podman/tasks/main.yml which should hopefully fix it:\n--- - name: Prefer plucky for podman copy: dest: /etc/apt/preferences.d/podman-plucky.pref content: | Package: podman buildah golang-github-containers-common crun libgpgme11t64 libgpg-error0 golang-github-containers-image catatonit conmon containers-storage Pin: release n=plucky Pin-Priority: 991 Package: libsubid4 netavark passt aardvark-dns containernetworking-plugins libslirp0 slirp4netns Pin: release n=plucky Pin-Priority: 991 Package: * Pin: release n=plucky Pin-Priority: 400 - name: Add plucky as a source template: dest: /etc/apt/sources.list.d/plucky.sources src: plucky.sources.j2 - name: Install podman apt: update_cache: true name: - podman state: present Next, we’ll need to add this to the roles list in initialize.yml. It should now look like this:\n--- - name: Initialize Ubuntu host hosts: all become: true roles: - name: base-install vars: authorized_keys: - ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIE9K1p8B8FRCWJ0Ax4obDu+UsLzGgXDIdTYkCZ8FF54b - podman Let’s test it with vagrant provision, then check:\nvagrant ssh -- podman --version podman version 5.4.1 Fantastic. This role was much less work than the previous one!\nWe need to talk about caddy I need my server to respond to HTTP and HTTPS, so we need something listening on port 80 and 443 to route http traffic to applications running in containers. I’ve had lots of experience using nginx and HAProxy, which are both excellent products. But I want this setup to be easily reproducible, fire-and-forget, and I haven’t found a great way to automate letsencrypt TLS certificates with these proxies. I have done it before, I just want something that’s more friendly to me.\nCaddy promises to do all the heavy lifting with almost no setup and seems to have modern defaults, with very little configuration required in general. I like that a lot, so I want to give it a go. A proxy is a part of the stack that we can easily replace later if we want. I hear traefik integrates with podman and letsencrypt too.\nWe could choose to run caddy in a container to make the host operating system even leaner. For now, I want to let unattended-upgrades deal with patching it. So we’ll set it up with apt. This probably gives us older, more stable, releases with fewer features. I think it should be easy to change our minds later if we discover something really cool in a release we don’t have.\nThere are many ways to configure caddy, but it looks like using /etc/caddy/Caddyfile will be the quickest way to get started with the apt package. I’m going to need to proxy to several backends, and I don’t want to centralize the configuration to this file, but thankfully it has an import directive. So this configuration here should do what I want:\n{ email robin@example.com servers { timeouts { read_body 5s read_header 5s write 5s idle 3m } } } import /etc/caddy/proxies.d/* If you want to use this, please enter your actual email, or letsencrypt won’t be able to reach you. Also check if you want to adjust those timeouts, these are global. We set read_body and read_header timeouts to low-ish values to make it a bit harder for mean clients to drain all our sockets. We’ll put the configuration in roles/caddy/files/Caddyfile.\nNext up, we need some more ✨tasks✨ in roles/caddy/tasks/main.yml:\n--- - name: Install caddy apt: state: present update_cache: true name: caddy - name: Ensure proxies.d file: dest: /etc/caddy/proxies.d/ state: directory - name: Set up global caddyfile copy: dest: /etc/caddy/Caddyfile src: Caddyfile notify: reload caddy - name: Enable caddy systemd: name: caddy enabled: yes You may have noticed that there’s a notify: reload caddy instruction here, so we’ll also need a handler in roles/caddy/handlers/main.yml:\n--- - name: reload caddy systemd: name: caddy state: reloaded Let’s keep expanding our initialize.yml playbook and add the caddy role:\n--- - name: Initialize Ubuntu host hosts: all become: true roles: - name: base-install vars: authorized_keys: - ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIE9K1p8B8FRCWJ0Ax4obDu+UsLzGgXDIdTYkCZ8FF54b - name: podman - name: caddy vagrant provision is happy, so I am happy too. Later when we set up applications, we’ll make them write their proxy configuration to /etc/caddy/proxies.d/appname, so we’ll revisit caddy once we’ve got an application running.\nBehold, an empty server that could run something We have all the pieces we need to run some sort of application now:\norchestration with systemd containerization with podman loadbalancing and http routing with caddy We did all this work, and all we have to show for it is that we’ve got a server listening on port 80 and 443, telling us nothing is found anywhere. That won’t do at all.\nCurrently, I need to run two applications on here:\neugene-web, source code available here. This is written in Rust and checks postgres SQL migrations for issues on a simple API. kollektivkart, source code available here. This is written in Python and DuckDB, and visualizes where delays in norwegian public transit occur. This backend has a “data pond”; it relies on around ~40GB of data in an S3 bucket and runs jobs to keep it updated. It makes the most sense to start deploying eugene-web, since it is a very basic stateless backend.\nI want to isolate these services from one another at the linux-user level, so we’ll need a user that can have systemd units. Since I foresee this being required for both the apps, we’ll fill in the app-user role now.\nTo be an app-user or not to be Since we do not want to install our applications with systemd on the root level, we have to jump through some hoops here. In particular, we need to enable linger for the users, so their systemd units can come up on reboots. Otherwise, the user must be logged in to have their units running. We also need to create the actual users, and we’ll want to set up some authorized keys for them.\n💡Linger is critical for this setup to work. The Arch Linux wiki has a technical explanation, look under section 2.2 Automatic start-up of systemd user instances.\nWe’ll also create the folders for where the systemd units and the quadlet definitions go. In total, we get this nice and cute roles/app-user/tasks/main.yml, but we’ll probably find a reason to revisit and make it terrible later on:\n--- - name: \"Create {{ user }}\" user: name: \"{{ user }}\" state: present shell: /bin/bash createhome: yes - name: \"Enable linger for {{ user }}\" command: loginctl enable-linger {{ user }} - name: \"Configure authorized keys for {{ user }}\" with_items: \"{{ authorized_keys }}\" authorized_key: user: \"{{ user }}\" key: \"{{ item }}\" state: present - name: \"Create quadlet home for {{ user }}\" file: path: \"/home/{{ user }}/.config/containers/systemd\" state: directory mode: \"0700\" owner: \"{{ user }}\" group: \"{{ user }}\" - name: \"Create systemd units home for {{ user }}\" file: path: \"/home/{{ user }}/.config/systemd/user\" state: directory mode: \"0700\" owner: \"{{ user }}\" group: \"{{ user }}\" - name: \"Create systemd wants home for {{ user }}\" file: path: \"/home/{{ user }}/.config/systemd/user/default.target.wants\" state: directory mode: \"0700\" group: \"{{ user }}\" owner: \"{{ user }}\" These definitions will be shared between the kollektivkart and the eugene backends, but we’re not adding them to initialize.yml. Instead, we’ll use the dependencies: key in roles/eugene/meta/main.yml to ensure that it includes an app-user role with a concrete variable for user.\nCareful With That Lock, Eugene Let’s start by making the directory tree we’ll need:\nmkdir -p roles/eugene/{tasks,meta,defaults,templates,files} Did you notice that we introduced two new subfolders in the role all at once? With no warning up front? Don’t worry, we’ll put something in those right away so we can discuss what they are for.\nIn roles/eugene/defaults/main.yml, we’ll put this snippet:\nuser: eugene This defines a value for the user parameter required by the app-user role, and allows whoever calls us to override it. Aren’t we being nice to our future selves? 🙌\nIn roles/eugene/meta/main.yml, we’ll put this:\ndependencies: - role: app-user This says that in order for the eugene role to work, it depends on the app-user role with the same user variable to exist. It means that when people ask for eugene, they also get app-user. They don’t have to worry about remembering it.\nI’ll put this into roles/app-user/meta/main.yml too:\nallow_duplicates: yes Otherwise, when we make the next application role and make it depend on app-user, it’ll think app-user has already done its thing, even if the {{ user }} variable is different.\nNow we can try to modify initialize.yml:\n--- - name: Initialize Ubuntu host hosts: all become: true roles: - name: base-install vars: authorized_keys: - ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIE9K1p8B8FRCWJ0Ax4obDu+UsLzGgXDIdTYkCZ8FF54b - name: podman - name: caddy - name: eugene Oh no, vagrant provision tells us we forgot about the authorized keys:\nTASK [app-user : Configure authorized keys for eugene] ************************* fatal: [default]: FAILED! =\u003e {\"msg\": \"'authorized_keys' is undefined\"} We don’t want to duplicate those, so we no longer want to set them directly on the base-install role. For now, we’ll stick to inlining it into the playbook and think about this issue later:\n--- - name: Initialize Ubuntu host hosts: all become: true vars: authorized_keys: - ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIE9K1p8B8FRCWJ0Ax4obDu+UsLzGgXDIdTYkCZ8FF54b roles: - name: base-install - name: podman - name: caddy - name: eugene 💡We could change all the roles from objects back into strings now, but I would like to explicitly pass vars: to them at some point, so I won’t.\nNotice how we just rudely moved it up two levels, and it became a global variable that all the roles can use. I really prefer passing variables like this explicitly to the roles. I think I’ll still be able to sleep at night, though, since this is a basic setup for only myself.\nNote that this means that the same set of keys will be used for both admin and the app-user roles. Probably not what we’d want if we were doing anything important! We can pass different sets of keys to the base-install and eugene, so that you can deploy eugene without being allowed sudo. But for now, vagrant provision is happy again, and it’s time to make the eugene-specific tasks.\nWhat is this mythical quadlet anyway? Finally getting to the fun part. By my count, that took around 260 lines of YAML. Feel free to take a break, you’ve deserved it!\n💡I don’t have a better way of explaining what a quadlet is than stating that it’s a nice systemd-wrapping around podman concepts like containers and networks. Previously, there used to be a way to use a generator to make systemd units out of podman definitions. It’s still there. It is handy to know about when things don’t work like expected. It will often tell you why your quadlets aren’t working. It will either tell you about errors or generate systemd units corresponding to your quadlets. To check all the quadlets in ~/.config/containers/systemd:\n/usr/lib/systemd/system-generators/podman-system-generator --user --dryrun We’ll make a eugene.container quadlet now. Let’s put it in roles/eugene/files/eugene.container:\n[Unit] Description=Eugene API for SQL migration validation After=network.target [Container] Image=ghcr.io/kaaveland/eugene-web:latest PublishPort=127.0.0.1:3000:3000 StopSignal=SIGKILL AutoUpdate=registry [Service] SyslogIdentifier=eugene-web CPUQuota=100% MemoryMax=128M [Install] WantedBy=default.target Here we’re describing what we’re running, then specifying in the [Container] section what image to run, and where to publish the port. We’re publishing it to the loopback address on 127.0.0.1, on port 3000 where caddy can find it. We’re also telling podman how to kill the container nicely, and that we should auto-update it from the registry.\n💡This [Container] uses just a tiny subset of what we can set on it. Check the documentation to discover more fun settings! You can discover more [Service] settings here. You can read about AutoUpdate too. By default, it’ll update containers daily at midnight.\nI feel like the networking here is suboptimal, but I’ll work on that some other time.\nIn the [Service] section, we set some limits for how many resources it can use. We’ll allow eugene to use one whole CPU core and 128MB RAM, which is significantly more than what it really needs.\nIn the [Install] section, we’re telling systemd that we want this thing to run on boot. Next, we’re going to need a caddy configuration. Let’s put that in roles/eugene/templates/eugene.caddy.j2:\napi{{ env_suffix }}.kaveland.no { encode handle /eugene/app/* { reverse_proxy localhost:3000 } log } There’s a potential problem that will require us to refactor later here. If we want to publish other apis to this hostname, we probably need to modify this file, which currently belongs to the eugene role. We’ll accept this technical debt and move on with our lives for now. I decided to introduce an env_suffix variable here so that I can make environments if I ever feel like it’s too exciting to have only a single deployment. If env_suffix isn’t defined, we’ll get an error, so we’ll need to pass it to this module. It seems… prudent for me to set up a machine on api-test.kaveland.no to check that everything works before I take over api.kaveland.no, so let’s pass it from initialize.yml:\n--- - name: Initialize Ubuntu host hosts: all become: true vars: authorized_keys: - ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIE9K1p8B8FRCWJ0Ax4obDu+UsLzGgXDIdTYkCZ8FF54b roles: - name: base-install - name: podman - name: caddy - name: eugene vars: env_suffix: -test Let’s tie it together in roles/eugene/tasks/main.yml:\n--- - name: Set up eugene quadlet unit copy: dest: \"/home/{{ user }}/.config/containers/systemd/eugene.container\" owner: \"{{ user }}\" group: \"{{ user }}\" mode: \"0600\" src: eugene.container - name: Reload systemd command: machinectl shell {{ user }}@ /bin/systemctl --user daemon-reload - name: Enable eugene command: machinectl shell {{ user }}@ /bin/systemctl --user enable eugene - name: Start eugene command: machinectl shell {{ user }}@ /bin/systemctl --user start eugene - name: Configure reverse proxy template: dest: \"/etc/caddy/proxies.d/eugene.caddy\" src: eugene.caddy owner: root group: root mode: \"0644\" notify: reload caddy Here we’re using machinectl to do systemd shenanigans because of DBus issues if we try to use become_user: \"{{ user }}\" with ansible. Ideally, we would like to run these commands with the ansible modules, but this is good enough for me. In here, we issue systemctl --user daemon-reload to make systemd discover our quadlet, then we enable and start it. Let’s check if it’s running:\nssh -p2222 eugene@localhost systemctl --user status eugene × eugene.service - Eugene API for SQL migration validation Loaded: loaded (/home/eugene/.config/containers/systemd/eugene.container; generated) Active: failed (Result: exit-code) since Tue 2025-05-13 22:45:34 CEST; 3min 13s ago Duration: 57ms Process: 79280 ExecStart=/usr/bin/podman run --name systemd-eugene --cidfile=/run/user/1002/eugene.cid --replace --rm --cgroups=split --stop-signal SIGKILL --sdnotify=conmon -d --label io.containers.autoupdate=registry --publish 127.0.0.1:3000:3000 ghcr.io/kaaveland/eugene-web:latest (code=exited, status=1/FAILURE) Process: 79303 ExecStopPost=/usr/bin/podman rm -v -f -i --cidfile=/run/user/1002/eugene.cid (code=exited, status=0/SUCCESS) Main PID: 79280 (code=exited, status=1/FAILURE) CPU: 117ms Bummer. The developer (me) hasn’t built the eugene-web image with arm64-support (although eugene-cli has both arm64, x86 and even a .exe). That was dumb of me. But otherwise, this is working as intended:\nssh -p2222 admin@localhost sudo reboot 0 ssh -p2222 admin@localhost whoami admin ssh -p2222 eugene@localhost systemctl --user status eugene × eugene.service - Eugene API for SQL migration validation Loaded: loaded (/home/eugene/.config/containers/systemd/eugene.container; generated) Active: failed (Result: exit-code) since Tue 2025-05-13 22:51:09 CEST; 6s ago Duration: 62ms Process: 1848 ExecStart=/usr/bin/podman run --name systemd-eugene --cidfile=/run/user/1002/eugene.cid --replace --rm --cgroups=split --stop-signal SIGKILL --sdnotify=conmon -d --label io.containers.autoupdate=registry --publish 127.0.0.1:3000:3000 ghcr.io/kaaveland/eugene-web:latest (code=exited, status=1/FAILURE) Process: 1949 ExecStopPost=/usr/bin/podman rm -v -f -i --cidfile=/run/user/1002/eugene.cid (code=exited, status=0/SUCCESS) Main PID: 1848 (code=exited, status=1/FAILURE) CPU: 209ms So, once we get this on an x86 machine, it’ll be fire-and-forget, with systemd and podman taking good care of eugene. Perfect!\neugene-web is almost the best-case for something we’ll host. It starts in milliseconds and can handle a few hundred requests a second on a single CPU core. We can write many useful applications that are like this! If we can really go a no-ops route here, the CI/CD side of things will just be a pipeline that pushes a docker image. That seems like something we should be able to manage!\nStill, it’s a little unsatisfactory to only be able to host the simplest possible application. The next post takes a look at something that is a little gnarlier to host, in particular it doesn’t restart almost instantly, and it has a job 😧\n","wordCount":"3112","inLanguage":"en","datePublished":"2025-05-14T00:00:00Z","dateModified":"2025-05-14T00:00:00Z","author":{"@type":"Person","name":"Robin Kåveland"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://kaveland.no/posts/2025-05-14-fire-and-forget-linux-p2/"},"publisher":{"@type":"Organization","name":"Robin's blog","logo":{"@type":"ImageObject","url":"https://kaveland.no/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://kaveland.no/ accesskey=h title="Robin's blog (Alt + H)">Robin's blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://kaveland.no/about/ title=about><span>about</span></a></li><li><a href=https://kaveland.no/projects/ title=projects><span>projects</span></a></li><li><a href=https://kaveland.no/eugene/ title=eugene><span>eugene</span></a></li><li><a href=https://kaveland.no/thumper/ title=thumper><span>thumper</span></a></li><li><a href=https://kaveland.no/tags/ title=tags><span>tags</span></a></li><li><a href=https://kaveland.no/archives/ title=archives><span>archives</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://kaveland.no/>Home</a>&nbsp;»&nbsp;<a href=https://kaveland.no/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">No-ops linux part 2: Hosting a simple container on a lean mean systemd machine</h1><div class=post-meta><span title='2025-05-14 00:00:00 +0000 UTC'>May 14, 2025</span>&nbsp;·&nbsp;15 min&nbsp;·&nbsp;3112 words&nbsp;·&nbsp;Robin Kåveland&nbsp;|&nbsp;<a href=https://github.com/kaaveland/kaaveland.github.io/content/posts/2025-05-14-fire-and-forget-linux-p2.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#its-time-to-introduce-podman>It&rsquo;s time to introduce ✨podman✨</a></li><li><a href=#we-need-to-talk-about-caddy>We need to talk about <a href=https://caddyserver.com/>caddy</a></a></li><li><a href=#behold-an-empty-server-that-could-run-something>Behold, an empty server that could run something</a></li><li><a href=#to-be-an-app-user-or-not-to-be>To be an app-user or not to be</a></li><li><a href=#careful-with-that-lock-eugene>Careful With That Lock, Eugene</a><ul><li><a href=#what-is-this-mythical-quadlet-anyway>What is this mythical quadlet anyway?</a></li></ul></li></ul></nav></div></details></div><div class=post-content><p>This post is part of the series on no-ops linux deployment. The <a href=/posts/2025-05-13-fire-and-forget-linux-p1>previous post</a> covered local development of linux server configuration and essential configuration. <a href=/posts/2025-05-14-fire-and-forget-linux-p2>This installment</a> covers a janky podman installation and configures a reverse proxy to send traffic to a simple container deployment. The <a href=/posts/2025-05-14-fire-and-forget-linux-p3>final post</a> covers a more challenging deployment with jobs and rolling restarts, and discusses the strengths and weaknesses of this approach to hosting.</p><p>At the completion of the previous post, we had automatic installation of a functional Ubuntu server with the bare essentials installed. We did this by writing a <code>base-install</code> ansible role. There&rsquo;s still a missing ingredient before we can start deploying containers, though!</p><h2 id=its-time-to-introduce-podman>It&rsquo;s time to introduce ✨podman✨<a hidden class=anchor aria-hidden=true href=#its-time-to-introduce-podman>#</a></h2><p><code>podman</code> is a tool for running containers. It&rsquo;s CLI-compatible with docker, and has deep and useful integrations with <code>systemd</code>, the <code>init</code> on most modern Linux installations. I want to use <code>systemd</code> to manage my containers for me with <a href=https://docs.podman.io/en/latest/markdown/podman-systemd.unit.5.html>podman systemd units</a>. This has nice features like auto-updating images, takes care of getting the log where I can read it, can restart failed containers and so on. <code>podman</code> will also run docker-compose files for you.</p><p>Ubuntu 24.04 (codename Noble) ships with podman 4.9, which is a year old and missing some features I want:</p><ul><li><code>systemd</code> template support for quadlet files (we&rsquo;ll get to this, don&rsquo;t worry)</li><li>Some limited support for using k8s YAML with podman (I know I said I wanted to avoid YAML, but this may come in handy)</li><li>Many quality of life improvements to quadlets</li></ul><p>Ubuntu 25.04 (codename Plucky) has podman 5.4, which has everything I want, but 25.04 isn&rsquo;t Long Term Support and not available at all cloud providers.</p><p>It&rsquo;s a little dirty, but what I&rsquo;ll do is to add the podman package from 25.04. This is not without risk, it could break things in the future. We&rsquo;ll have to hope that grizzled ops veterans avert their eyes and the gods of fortune and luck are with us.</p><p>We&rsquo;ll add the 25.04 sources to apt, using the new-fangled and cool <code>.sources</code> format. I need to use a template for this because my laptop is running on arm, but I&rsquo;m probably going to end up provisioning to an x86 machine, and there are different package URIs for those. Let&rsquo;s create <code>roles/podman/templates/plucky.sources.j2</code> with this content:</p><pre tabindex=0><code>Types: deb
{% if ansible_architecture == &#39;aarch64&#39; or ansible_architecture == &#39;arm64&#39; %}
URIs: http://ports.ubuntu.com/ubuntu-ports
{% else %}
URIs: http://archive.ubuntu.com/ubuntu
{% endif %}
Suites: plucky plucky-updates
Components: main universe restricted
Signed-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg
</code></pre><p>The <code>{% if ... }</code> is jinja2-syntax, and ansible knows what kind of architecture the machine has. But just adding this, we risk upgrading tons of packages to the 25.04 distribution, and we don&rsquo;t want that. We can limit the blast radius by setting up a <code>.pref</code> file that pins only the packages we think we need to 25.04. I found a list at <a href=https://github.com/containers/podman/discussions/25582>this issue</a> that looks good. We&rsquo;ll add this to <code>roles/podman/tasks/main.yml</code> which should hopefully fix it:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nn>---</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Prefer plucky for podman</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>copy</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>dest</span><span class=p>:</span><span class=w> </span><span class=l>/etc/apt/preferences.d/podman-plucky.pref</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>content</span><span class=p>:</span><span class=w> </span><span class=p>|</span><span class=sd>
</span></span></span><span class=line><span class=cl><span class=sd>      Package: podman buildah golang-github-containers-common crun libgpgme11t64 libgpg-error0 golang-github-containers-image catatonit conmon containers-storage
</span></span></span><span class=line><span class=cl><span class=sd>      Pin: release n=plucky
</span></span></span><span class=line><span class=cl><span class=sd>      Pin-Priority: 991
</span></span></span><span class=line><span class=cl><span class=sd>
</span></span></span><span class=line><span class=cl><span class=sd>      Package: libsubid4 netavark passt aardvark-dns containernetworking-plugins libslirp0 slirp4netns
</span></span></span><span class=line><span class=cl><span class=sd>      Pin: release n=plucky
</span></span></span><span class=line><span class=cl><span class=sd>      Pin-Priority: 991
</span></span></span><span class=line><span class=cl><span class=sd>
</span></span></span><span class=line><span class=cl><span class=sd>      Package: *
</span></span></span><span class=line><span class=cl><span class=sd>      Pin: release n=plucky
</span></span></span><span class=line><span class=cl><span class=sd>      Pin-Priority: 400</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Add plucky as a source</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>template</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>dest</span><span class=p>:</span><span class=w> </span><span class=l>/etc/apt/sources.list.d/plucky.sources</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>src</span><span class=p>:</span><span class=w> </span><span class=l>plucky.sources.j2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Install podman</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>apt</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>update_cache</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>name</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>podman</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>state</span><span class=p>:</span><span class=w> </span><span class=l>present</span><span class=w>
</span></span></span></code></pre></div><p>Next, we&rsquo;ll need to add this to the roles list in <code>initialize.yml</code>. It should now look like this:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nn>---</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Initialize Ubuntu host</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>hosts</span><span class=p>:</span><span class=w> </span><span class=l>all</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>become</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>roles</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>base-install</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>vars</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>authorized_keys</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span>- <span class=l>ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIE9K1p8B8FRCWJ0Ax4obDu+UsLzGgXDIdTYkCZ8FF54b</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=l>podman</span><span class=w>
</span></span></span></code></pre></div><p>Let&rsquo;s test it with <code>vagrant provision</code>, then check:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>vagrant ssh -- podman --version
</span></span><span class=line><span class=cl>podman version 5.4.1
</span></span></code></pre></div><p>Fantastic. This role was much less work than the previous one!</p><h2 id=we-need-to-talk-about-caddy>We need to talk about <a href=https://caddyserver.com/>caddy</a><a hidden class=anchor aria-hidden=true href=#we-need-to-talk-about-caddy>#</a></h2><p>I need my server to respond to HTTP and HTTPS, so we need something listening on port 80 and 443 to route http traffic to applications running in containers. I&rsquo;ve had lots of experience using nginx and HAProxy, which are both excellent products. But I want this setup to be easily reproducible, fire-and-forget, and I haven&rsquo;t found a great way to automate letsencrypt TLS certificates with these proxies. I <em>have</em> done it before, I just want something that&rsquo;s more friendly to me.</p><p>Caddy promises to do all the heavy lifting with almost no setup and seems to have modern defaults, with very little configuration required in general. I like that a lot, so I want to give it a go. A proxy is a part of the stack that we can easily replace later if we want. I hear <a href=https://gerov.eu/posts/traefik-for-podman/>traefik integrates with podman and letsencrypt</a> too.</p><p>We could choose to run caddy in a container to make the host operating system even leaner. For now, I want to let unattended-upgrades deal with patching it. So we&rsquo;ll set it up with <code>apt</code>. This probably gives us older, more stable, releases with fewer features. I think it should be easy to change our minds later if we discover something really cool in a release we don&rsquo;t have.</p><p>There are many ways to configure caddy, but it looks like using <code>/etc/caddy/Caddyfile</code> will be the quickest way to get started with the <code>apt</code> package. I&rsquo;m going to need to proxy to several backends, and I don&rsquo;t want to centralize the configuration to this file, but thankfully it has an <code>import</code> directive. So this configuration here should do what I want:</p><pre tabindex=0><code>{
	email robin@example.com
	servers {
		timeouts {
			read_body 5s
			read_header 5s
			write 5s
			idle 3m
		}
	}
}

import /etc/caddy/proxies.d/*
</code></pre><p>If you want to use this, please enter your actual email, or letsencrypt won&rsquo;t be able to reach you. Also check if you want to adjust those timeouts, these are global. We set <code>read_body</code> and <code>read_header</code> timeouts to low-ish values to make it a bit harder for mean clients to drain all our sockets. We&rsquo;ll put the configuration in <code>roles/caddy/files/Caddyfile</code>.</p><p>Next up, we need some more ✨tasks✨ in <code>roles/caddy/tasks/main.yml</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nn>---</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Install caddy</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>apt</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>state</span><span class=p>:</span><span class=w> </span><span class=l>present</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>update_cache</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>caddy</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Ensure proxies.d</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>file</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>dest</span><span class=p>:</span><span class=w> </span><span class=l>/etc/caddy/proxies.d/</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>state</span><span class=p>:</span><span class=w> </span><span class=l>directory</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Set up global caddyfile</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>copy</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>dest</span><span class=p>:</span><span class=w> </span><span class=l>/etc/caddy/Caddyfile</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>src</span><span class=p>:</span><span class=w> </span><span class=l>Caddyfile</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>notify</span><span class=p>:</span><span class=w> </span><span class=l>reload caddy</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Enable caddy</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>systemd</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>caddy</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>enabled</span><span class=p>:</span><span class=w> </span><span class=kc>yes</span><span class=w>
</span></span></span></code></pre></div><p>You may have noticed that there&rsquo;s a <code>notify: reload caddy</code> instruction here, so we&rsquo;ll also need a handler in <code>roles/caddy/handlers/main.yml</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nn>---</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>reload caddy</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>systemd</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>caddy</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>state</span><span class=p>:</span><span class=w> </span><span class=l>reloaded</span><span class=w>
</span></span></span></code></pre></div><p>Let&rsquo;s keep expanding our <code>initialize.yml</code> playbook and add the caddy role:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nn>---</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Initialize Ubuntu host</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>hosts</span><span class=p>:</span><span class=w> </span><span class=l>all</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>become</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>roles</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>base-install</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>vars</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>authorized_keys</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span>- <span class=l>ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIE9K1p8B8FRCWJ0Ax4obDu+UsLzGgXDIdTYkCZ8FF54b</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>podman</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>caddy</span><span class=w>
</span></span></span></code></pre></div><p><code>vagrant provision</code> is happy, so I am happy too. Later when we set up applications, we&rsquo;ll make them write their proxy configuration to <code>/etc/caddy/proxies.d/appname</code>, so we&rsquo;ll revisit caddy once we&rsquo;ve got an application running.</p><h2 id=behold-an-empty-server-that-could-run-something>Behold, an empty server that could run something<a hidden class=anchor aria-hidden=true href=#behold-an-empty-server-that-could-run-something>#</a></h2><p>We have all the pieces we need to run some sort of application now:</p><ul><li>orchestration with <code>systemd</code></li><li>containerization with <code>podman</code></li><li>loadbalancing and http routing with <code>caddy</code></li></ul><p>We did all this work, and all we have to show for it is that we&rsquo;ve got a server listening on port 80 and 443, telling us nothing is found anywhere. That won&rsquo;t do at all.</p><p>Currently, I need to run two applications on here:</p><ul><li><a href=https://kaveland.no/eugene/web.html>eugene-web</a>, source code available <a href=https://github.com/kaaveland/eugene/tree/main>here</a>. This is written in Rust and checks postgres SQL migrations for issues on a simple API.</li><li><a href=https://kollektivkart.arktekk.no/>kollektivkart</a>, source code available <a href=https://github.com/kaaveland/bus-eta>here</a>. This is written in Python and DuckDB, and visualizes where delays in norwegian public transit occur. This backend has a &ldquo;data pond&rdquo;; it relies on around ~40GB of data in an S3 bucket and runs jobs to keep it updated.</li></ul><p>It makes the most sense to start deploying <code>eugene-web</code>, since it is a very basic stateless backend.</p><p>I want to isolate these services from one another at the linux-user level, so we&rsquo;ll need a user that can have <code>systemd</code> units. Since I foresee this being required for both the apps, we&rsquo;ll fill in the <code>app-user</code> role now.</p><h2 id=to-be-an-app-user-or-not-to-be>To be an app-user or not to be<a hidden class=anchor aria-hidden=true href=#to-be-an-app-user-or-not-to-be>#</a></h2><p>Since we do not want to install our applications with systemd on the root level, we have to jump through some hoops here. In particular, we need to enable <em>linger</em> for the users, so their systemd units can come up on reboots. Otherwise, the user must be logged in to have their units running. We also need to create the actual users, and we&rsquo;ll want to set up some authorized keys for them.</p><blockquote><p>💡Linger is critical for this setup to work. The <a href=https://wiki.archlinux.org/title/Systemd/User>Arch Linux wiki</a> has a technical explanation, look under section 2.2 Automatic start-up of systemd user instances.</p></blockquote><p>We&rsquo;ll also create the folders for where the systemd units and the quadlet definitions go. In total, we get this nice and cute <code>roles/app-user/tasks/main.yml</code>, but we&rsquo;ll probably find a reason to revisit and make it terrible later on:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nn>---</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;Create {{ user }}&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>user</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;{{ user }}&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>state</span><span class=p>:</span><span class=w> </span><span class=l>present</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>shell</span><span class=p>:</span><span class=w> </span><span class=l>/bin/bash</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>createhome</span><span class=p>:</span><span class=w> </span><span class=kc>yes</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;Enable linger for {{ user }}&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>command</span><span class=p>:</span><span class=w> </span><span class=l>loginctl enable-linger {{ user }}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;Configure authorized keys for {{ user }}&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>with_items</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;{{ authorized_keys }}&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>authorized_key</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>user</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;{{ user }}&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>key</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;{{ item }}&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>state</span><span class=p>:</span><span class=w> </span><span class=l>present</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;Create quadlet home for {{ user }}&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>file</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;/home/{{ user }}/.config/containers/systemd&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>state</span><span class=p>:</span><span class=w> </span><span class=l>directory</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>mode</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;0700&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>owner</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;{{ user }}&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>group</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;{{ user }}&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;Create systemd units home for {{ user }}&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>file</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;/home/{{ user }}/.config/systemd/user&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>state</span><span class=p>:</span><span class=w> </span><span class=l>directory</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>mode</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;0700&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>owner</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;{{ user }}&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>group</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;{{ user }}&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;Create systemd wants home for {{ user }}&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>file</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>path</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;/home/{{ user }}/.config/systemd/user/default.target.wants&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>state</span><span class=p>:</span><span class=w> </span><span class=l>directory</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>mode</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;0700&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>group</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;{{ user }}&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>owner</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;{{ user }}&#34;</span><span class=w>
</span></span></span></code></pre></div><p>These definitions will be shared between the kollektivkart and the eugene backends, but we&rsquo;re not adding them to <code>initialize.yml</code>. Instead, we&rsquo;ll use the <code>dependencies:</code> key in <code>roles/eugene/meta/main.yml</code> to ensure that it <em>includes</em> an <code>app-user</code> role with a concrete variable for <code>user</code>.</p><h2 id=careful-with-that-lock-eugene>Careful With That Lock, Eugene<a hidden class=anchor aria-hidden=true href=#careful-with-that-lock-eugene>#</a></h2><p>Let&rsquo;s start by making the directory tree we&rsquo;ll need:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>mkdir -p roles/eugene/<span class=o>{</span>tasks,meta,defaults,templates,files<span class=o>}</span>
</span></span></code></pre></div><p>Did you notice that we introduced two new subfolders in the role all at once? With no warning up front? Don&rsquo;t worry, we&rsquo;ll put something in those right away so we can discuss what they are for.</p><p>In <code>roles/eugene/defaults/main.yml</code>, we&rsquo;ll put this snippet:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>user</span><span class=p>:</span><span class=w> </span><span class=l>eugene</span><span class=w>
</span></span></span></code></pre></div><p>This defines a value for the <code>user</code> parameter required by the <code>app-user</code> role, <em>and</em> allows whoever calls us to override it. Aren&rsquo;t we being nice to our future selves? 🙌</p><p>In <code>roles/eugene/meta/main.yml</code>, we&rsquo;ll put this:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>dependencies</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=nt>role</span><span class=p>:</span><span class=w> </span><span class=l>app-user</span><span class=w>
</span></span></span></code></pre></div><p>This says that in order for the <code>eugene</code> role to work, it depends on the <code>app-user</code> role with the same <code>user</code> variable to exist. It means that when people ask for <code>eugene</code>, they also get <code>app-user</code>. They don&rsquo;t have to worry about remembering it.</p><p>I&rsquo;ll put this into <code>roles/app-user/meta/main.yml</code> too:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>allow_duplicates</span><span class=p>:</span><span class=w> </span><span class=kc>yes</span><span class=w>
</span></span></span></code></pre></div><p>Otherwise, when we make the next application role and make it depend on <code>app-user</code>, it&rsquo;ll think <code>app-user</code> has already done its thing, even if the <code>{{ user }}</code> variable is different.</p><p><em>Now</em> we can try to modify <code>initialize.yml</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nn>---</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Initialize Ubuntu host</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>hosts</span><span class=p>:</span><span class=w> </span><span class=l>all</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>become</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>roles</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>base-install</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>vars</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>authorized_keys</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span>- <span class=l>ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIE9K1p8B8FRCWJ0Ax4obDu+UsLzGgXDIdTYkCZ8FF54b</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>podman</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>caddy</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>eugene</span><span class=w>
</span></span></span></code></pre></div><p>Oh no, <code>vagrant provision</code> tells us we forgot about the authorized keys:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>TASK [app-user </span><span class=p>:</span><span class=w> </span><span class=l>Configure authorized keys for eugene] *************************</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>fatal: [default]</span><span class=p>:</span><span class=w> </span><span class=l>FAILED! =&gt; {&#34;msg&#34;: &#34;&#39;authorized_keys&#39; is undefined&#34;}</span><span class=w>
</span></span></span></code></pre></div><p>We don&rsquo;t want to duplicate those, so we no longer want to set them directly on the <code>base-install</code> role. For now, we&rsquo;ll stick to inlining it into the playbook and think about this issue later:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nn>---</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Initialize Ubuntu host</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>hosts</span><span class=p>:</span><span class=w> </span><span class=l>all</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>become</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>vars</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>authorized_keys</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIE9K1p8B8FRCWJ0Ax4obDu+UsLzGgXDIdTYkCZ8FF54b</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>roles</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>base-install</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>podman</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>caddy</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>eugene</span><span class=w>
</span></span></span></code></pre></div><blockquote><p>💡We could change all the <code>roles</code> from objects back into strings now, but I would like to explicitly pass <code>vars:</code> to them at some point, so <em>I</em> won&rsquo;t.</p></blockquote><p>Notice how we just rudely moved it up two levels, and it became a global variable that all the roles can use. I really prefer passing variables like this explicitly to the roles. I think I&rsquo;ll still be able to sleep at night, though, since this is a basic setup for only myself.</p><p>Note that this means that the same set of keys will be used for both <code>admin</code> and the <code>app-user</code> roles. Probably not what we&rsquo;d want if we were doing anything important! We can pass different sets of keys to the <code>base-install</code> and <code>eugene</code>, so that you can deploy <code>eugene</code> without being allowed <code>sudo</code>. But for now, <code>vagrant provision</code> is happy again, and it&rsquo;s time to make the <code>eugene</code>-specific tasks.</p><h3 id=what-is-this-mythical-quadlet-anyway>What is this mythical quadlet anyway?<a hidden class=anchor aria-hidden=true href=#what-is-this-mythical-quadlet-anyway>#</a></h3><p><em>Finally</em> getting to the fun part. By my count, that took around 260 lines of YAML. Feel free to take a break, you&rsquo;ve deserved it!</p><blockquote><p>💡I don&rsquo;t have a better way of explaining what a quadlet is than stating that it&rsquo;s a nice systemd-wrapping around podman concepts like containers and networks. Previously, there used to be a way to use a <a href=https://docs.podman.io/en/latest/markdown/podman-generate-systemd.1.html>generator</a> to make systemd units out of podman definitions. It&rsquo;s still there. It is handy to know about when things don&rsquo;t work like expected. It will often tell you why your quadlets aren&rsquo;t working. It will either tell you about errors or generate systemd units corresponding to your quadlets. To check all the quadlets in <code>~/.config/containers/systemd</code>:</p></blockquote><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>/usr/lib/systemd/system-generators/podman-system-generator --user --dryrun
</span></span></code></pre></div><p>We&rsquo;ll make a <code>eugene.container</code> quadlet now. Let&rsquo;s put it in <code>roles/eugene/files/eugene.container</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-toml data-lang=toml><span class=line><span class=cl><span class=p>[</span><span class=nx>Unit</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nx>Description</span><span class=p>=</span><span class=nx>Eugene</span> <span class=nx>API</span> <span class=nx>for</span> <span class=nx>SQL</span> <span class=nx>migration</span> <span class=nx>validation</span>
</span></span><span class=line><span class=cl><span class=nx>After</span><span class=p>=</span><span class=nx>network</span><span class=p>.</span><span class=nx>target</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=nx>Container</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nx>Image</span><span class=p>=</span><span class=nx>ghcr</span><span class=p>.</span><span class=nx>io</span><span class=err>/</span><span class=nx>kaaveland</span><span class=err>/</span><span class=nx>eugene-web</span><span class=err>:</span><span class=nx>latest</span>
</span></span><span class=line><span class=cl><span class=nx>PublishPort</span><span class=p>=</span><span class=mf>127.0</span><span class=p>.</span><span class=mf>0.1</span><span class=err>:</span><span class=mi>3000</span><span class=err>:</span><span class=mi>3000</span>
</span></span><span class=line><span class=cl><span class=nx>StopSignal</span><span class=p>=</span><span class=nx>SIGKILL</span>
</span></span><span class=line><span class=cl><span class=nx>AutoUpdate</span><span class=p>=</span><span class=nx>registry</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=nx>Service</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nx>SyslogIdentifier</span><span class=p>=</span><span class=nx>eugene-web</span>
</span></span><span class=line><span class=cl><span class=nx>CPUQuota</span><span class=p>=</span><span class=mi>100</span><span class=err>%</span>
</span></span><span class=line><span class=cl><span class=nx>MemoryMax</span><span class=p>=</span><span class=mi>128</span><span class=nx>M</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>[</span><span class=nx>Install</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nx>WantedBy</span><span class=p>=</span><span class=nx>default</span><span class=p>.</span><span class=nx>target</span>
</span></span></code></pre></div><p>Here we&rsquo;re describing what we&rsquo;re running, then specifying in the <code>[Container]</code> section what image to run, and where to publish the port. We&rsquo;re publishing it to the loopback address on <code>127.0.0.1</code>, on port 3000 where caddy can find it. We&rsquo;re also telling podman how to kill the container nicely, and that we should auto-update it from the registry.</p><blockquote><p>💡This <code>[Container]</code> uses just a <em>tiny</em> subset of what we can set on it. Check the <a href=https://docs.podman.io/en/latest/markdown/podman-systemd.unit.5.html#container-units-container>documentation</a> to discover more fun settings! You can discover more <code>[Service]</code> settings <a href=https://www.freedesktop.org/software/systemd/man/latest/systemd.service.html>here</a>. You can read about <a href=https://docs.podman.io/en/latest/markdown/podman-auto-update.1.html>AutoUpdate</a> too. By default, it&rsquo;ll update containers daily at midnight.</p></blockquote><p>I feel like the networking here is suboptimal, but I&rsquo;ll work on that some other time.</p><p>In the <code>[Service]</code> section, we set some limits for how many resources it can use. We&rsquo;ll allow <code>eugene</code> to use one whole CPU core and 128MB RAM, which is significantly more than what it really needs.</p><p>In the <code>[Install]</code> section, we&rsquo;re telling <code>systemd</code> that we want this thing to run on boot. Next, we&rsquo;re going to need a caddy configuration. Let&rsquo;s put that in <code>roles/eugene/templates/eugene.caddy.j2</code>:</p><pre tabindex=0><code>api{{ env_suffix }}.kaveland.no {
    encode
    handle /eugene/app/* {
        reverse_proxy localhost:3000
    }
    log
}
</code></pre><p>There&rsquo;s a potential problem that will require us to refactor later here. If we want to publish other apis to this hostname, we probably need to modify this file, which currently belongs to the <code>eugene</code> role. We&rsquo;ll accept this technical debt and move on with our lives for now. I decided to introduce an <code>env_suffix</code> variable here so that I can make environments if I ever feel like it&rsquo;s too exciting to have only a single deployment. If <code>env_suffix</code> isn&rsquo;t defined, we&rsquo;ll get an error, so we&rsquo;ll need to pass it to this module. It seems&mldr; prudent for me to set up a machine on <code>api-test.kaveland.no</code> to check that everything works <em>before</em> I take over <code>api.kaveland.no</code>, so let&rsquo;s pass it from <code>initialize.yml</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nn>---</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Initialize Ubuntu host</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>hosts</span><span class=p>:</span><span class=w> </span><span class=l>all</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>become</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>vars</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>authorized_keys</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIE9K1p8B8FRCWJ0Ax4obDu+UsLzGgXDIdTYkCZ8FF54b</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>roles</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>base-install</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>podman</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>caddy</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>eugene</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>vars</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>env_suffix</span><span class=p>:</span><span class=w> </span>-<span class=l>test </span><span class=w>
</span></span></span></code></pre></div><p>Let&rsquo;s tie it together in <code>roles/eugene/tasks/main.yml</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nn>---</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Set up eugene quadlet unit</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>copy</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>dest</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;/home/{{ user }}/.config/containers/systemd/eugene.container&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>owner</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;{{ user }}&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>group</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;{{ user }}&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>mode</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;0600&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>src</span><span class=p>:</span><span class=w> </span><span class=l>eugene.container</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Reload systemd</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>command</span><span class=p>:</span><span class=w> </span><span class=l>machinectl shell {{ user }}@ /bin/systemctl --user daemon-reload</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Enable eugene</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>command</span><span class=p>:</span><span class=w> </span><span class=l>machinectl shell {{ user }}@ /bin/systemctl --user enable eugene</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Start eugene</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>command</span><span class=p>:</span><span class=w> </span><span class=l>machinectl shell {{ user }}@ /bin/systemctl --user start eugene</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>Configure reverse proxy</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>template</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>dest</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;/etc/caddy/proxies.d/eugene.caddy&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>src</span><span class=p>:</span><span class=w> </span><span class=l>eugene.caddy</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>owner</span><span class=p>:</span><span class=w> </span><span class=l>root</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>group</span><span class=p>:</span><span class=w> </span><span class=l>root</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>mode</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;0644&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>notify</span><span class=p>:</span><span class=w> </span><span class=l>reload caddy</span><span class=w>
</span></span></span></code></pre></div><p>Here we&rsquo;re using <code>machinectl</code> to do systemd shenanigans because of DBus issues if we try to use <code>become_user: "{{ user }}"</code> with ansible. Ideally, we would like to run these commands with the ansible modules, but this is good enough for me. In here, we issue <code>systemctl --user daemon-reload</code> to make <code>systemd</code> discover our quadlet, then we enable and start it. Let&rsquo;s check if it&rsquo;s running:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>ssh -p2222 eugene@localhost systemctl --user status eugene
</span></span><span class=line><span class=cl>× eugene.service - Eugene API <span class=k>for</span> SQL migration validation
</span></span><span class=line><span class=cl>     Loaded: loaded <span class=o>(</span>/home/eugene/.config/containers/systemd/eugene.container<span class=p>;</span> generated<span class=o>)</span>
</span></span><span class=line><span class=cl>     Active: failed <span class=o>(</span>Result: exit-code<span class=o>)</span> since Tue 2025-05-13 22:45:34 CEST<span class=p>;</span> 3min 13s ago
</span></span><span class=line><span class=cl>   Duration: 57ms
</span></span><span class=line><span class=cl>    Process: <span class=m>79280</span> <span class=nv>ExecStart</span><span class=o>=</span>/usr/bin/podman run --name systemd-eugene --cidfile<span class=o>=</span>/run/user/1002/eugene.cid --replace --rm --cgroups<span class=o>=</span>split --stop-signal SIGKILL --sdnotify<span class=o>=</span>conmon -d --label io.containers.autoupdate<span class=o>=</span>registry --publish 127.0.0.1:3000:3000  ghcr.io/kaaveland/eugene-web:latest <span class=o>(</span><span class=nv>code</span><span class=o>=</span>exited, <span class=nv>status</span><span class=o>=</span>1/FAILURE<span class=o>)</span>
</span></span><span class=line><span class=cl>    Process: <span class=m>79303</span> <span class=nv>ExecStopPost</span><span class=o>=</span>/usr/bin/podman rm -v -f -i --cidfile<span class=o>=</span>/run/user/1002/eugene.cid <span class=o>(</span><span class=nv>code</span><span class=o>=</span>exited, <span class=nv>status</span><span class=o>=</span>0/SUCCESS<span class=o>)</span>
</span></span><span class=line><span class=cl>   Main PID: <span class=m>79280</span> <span class=o>(</span><span class=nv>code</span><span class=o>=</span>exited, <span class=nv>status</span><span class=o>=</span>1/FAILURE<span class=o>)</span>
</span></span><span class=line><span class=cl>        CPU: 117ms
</span></span></code></pre></div><p>Bummer. The developer (me) hasn&rsquo;t built the eugene-web image with arm64-support (although eugene-cli has both arm64, x86 and even a .exe). That was dumb of me. But otherwise, this is working as intended:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl> ssh -p2222 admin@localhost sudo reboot <span class=m>0</span>
</span></span><span class=line><span class=cl> ssh -p2222 admin@localhost whoami
</span></span><span class=line><span class=cl> admin
</span></span><span class=line><span class=cl> ssh -p2222 eugene@localhost systemctl --user status eugene
</span></span><span class=line><span class=cl>× eugene.service - Eugene API <span class=k>for</span> SQL migration validation
</span></span><span class=line><span class=cl>     Loaded: loaded <span class=o>(</span>/home/eugene/.config/containers/systemd/eugene.container<span class=p>;</span> generated<span class=o>)</span>
</span></span><span class=line><span class=cl>     Active: failed <span class=o>(</span>Result: exit-code<span class=o>)</span> since Tue 2025-05-13 22:51:09 CEST<span class=p>;</span> 6s ago
</span></span><span class=line><span class=cl>   Duration: 62ms
</span></span><span class=line><span class=cl>    Process: <span class=m>1848</span> <span class=nv>ExecStart</span><span class=o>=</span>/usr/bin/podman run --name systemd-eugene --cidfile<span class=o>=</span>/run/user/1002/eugene.cid --replace --rm --cgroups<span class=o>=</span>split --stop-signal SIGKILL --sdnotify<span class=o>=</span>conmon -d --label io.containers.autoupdate<span class=o>=</span>registry --publish 127.0.0.1:3000:3000 ghcr.io/kaaveland/eugene-web:latest <span class=o>(</span><span class=nv>code</span><span class=o>=</span>exited, <span class=nv>status</span><span class=o>=</span>1/FAILURE<span class=o>)</span>
</span></span><span class=line><span class=cl>    Process: <span class=m>1949</span> <span class=nv>ExecStopPost</span><span class=o>=</span>/usr/bin/podman rm -v -f -i --cidfile<span class=o>=</span>/run/user/1002/eugene.cid <span class=o>(</span><span class=nv>code</span><span class=o>=</span>exited, <span class=nv>status</span><span class=o>=</span>0/SUCCESS<span class=o>)</span>
</span></span><span class=line><span class=cl>   Main PID: <span class=m>1848</span> <span class=o>(</span><span class=nv>code</span><span class=o>=</span>exited, <span class=nv>status</span><span class=o>=</span>1/FAILURE<span class=o>)</span>
</span></span><span class=line><span class=cl>        CPU: 209ms
</span></span></code></pre></div><p>So, once we get this on an x86 machine, it&rsquo;ll be fire-and-forget, with systemd and podman taking good care of eugene. Perfect!</p><p><code>eugene-web</code> is almost the best-case for something we&rsquo;ll host. It starts in milliseconds and can handle a few hundred requests a second on a single CPU core. We can write many useful applications that are like this! If we can really go a no-ops route here, the CI/CD side of things will just be a pipeline that pushes a docker image. That seems like something we should be able to manage!</p><p>Still, it&rsquo;s a little unsatisfactory to only be able to host the simplest possible application. The <a href=/posts/2025-05-14-fire-and-forget-linux-p3>next post</a> takes a look at something that is a little gnarlier to host, in particular it doesn&rsquo;t restart almost instantly, and it <em>has a job</em> 😧</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://kaveland.no/tags/cloud/>Cloud</a></li><li><a href=https://kaveland.no/tags/linux/>Linux</a></li><li><a href=https://kaveland.no/tags/ops/>Ops</a></li><li><a href=https://kaveland.no/tags/cdn/>Cdn</a></li><li><a href=https://kaveland.no/tags/duckdb/>Duckdb</a></li><li><a href=https://kaveland.no/tags/caddy/>Caddy</a></li><li><a href=https://kaveland.no/tags/ansible/>Ansible</a></li></ul><nav class=paginav><a class=prev href=https://kaveland.no/posts/2025-05-14-fire-and-forget-linux-p3/><span class=title>« Prev</span><br><span>No-ops linux part 3: It puts the data in the pond. Nightly.</span>
</a><a class=next href=https://kaveland.no/posts/2025-05-13-fire-and-forget-linux-p1/><span class=title>Next »</span><br><span>No-ops Linux part 1: Automation, security and essentials</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share No-ops linux part 2: Hosting a simple container on a lean mean systemd machine on x" href="https://x.com/intent/tweet/?text=No-ops%20linux%20part%202%3a%20Hosting%20a%20simple%20container%20on%20a%20lean%20mean%20systemd%20machine&amp;url=https%3a%2f%2fkaveland.no%2fposts%2f2025-05-14-fire-and-forget-linux-p2%2f&amp;hashtags=cloud%2clinux%2cops%2ccdn%2cduckdb%2ccaddy%2cansible"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share No-ops linux part 2: Hosting a simple container on a lean mean systemd machine on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fkaveland.no%2fposts%2f2025-05-14-fire-and-forget-linux-p2%2f&amp;title=No-ops%20linux%20part%202%3a%20Hosting%20a%20simple%20container%20on%20a%20lean%20mean%20systemd%20machine&amp;summary=No-ops%20linux%20part%202%3a%20Hosting%20a%20simple%20container%20on%20a%20lean%20mean%20systemd%20machine&amp;source=https%3a%2f%2fkaveland.no%2fposts%2f2025-05-14-fire-and-forget-linux-p2%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share No-ops linux part 2: Hosting a simple container on a lean mean systemd machine on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fkaveland.no%2fposts%2f2025-05-14-fire-and-forget-linux-p2%2f&title=No-ops%20linux%20part%202%3a%20Hosting%20a%20simple%20container%20on%20a%20lean%20mean%20systemd%20machine"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share No-ops linux part 2: Hosting a simple container on a lean mean systemd machine on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fkaveland.no%2fposts%2f2025-05-14-fire-and-forget-linux-p2%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share No-ops linux part 2: Hosting a simple container on a lean mean systemd machine on whatsapp" href="https://api.whatsapp.com/send?text=No-ops%20linux%20part%202%3a%20Hosting%20a%20simple%20container%20on%20a%20lean%20mean%20systemd%20machine%20-%20https%3a%2f%2fkaveland.no%2fposts%2f2025-05-14-fire-and-forget-linux-p2%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share No-ops linux part 2: Hosting a simple container on a lean mean systemd machine on telegram" href="https://telegram.me/share/url?text=No-ops%20linux%20part%202%3a%20Hosting%20a%20simple%20container%20on%20a%20lean%20mean%20systemd%20machine&amp;url=https%3a%2f%2fkaveland.no%2fposts%2f2025-05-14-fire-and-forget-linux-p2%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share No-ops linux part 2: Hosting a simple container on a lean mean systemd machine on ycombinator" href="https://news.ycombinator.com/submitlink?t=No-ops%20linux%20part%202%3a%20Hosting%20a%20simple%20container%20on%20a%20lean%20mean%20systemd%20machine&u=https%3a%2f%2fkaveland.no%2fposts%2f2025-05-14-fire-and-forget-linux-p2%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://kaveland.no/>Robin's blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>