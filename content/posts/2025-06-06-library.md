+++
title = "The librarian immediately attempts to sell you a vuvuzela"
date = "2025-06-06T20:30:00Z"
tags = ["writing", "thoughts", "ai"]
+++

Imagine entering the biggest library in the world. You peer down an incredibly long aisle with wooden bookshelves brimming with books. You can see multiple such corridors, all lit with a comfortable warm light. There's a rich smell of old paper. You can hear some muted voices, perhaps arguing in a whisper. It's perfect, but vast and difficult to make sense of. Just this day, it doesn't feel like such a terrible ordeal to just wander for a while, see where your legs take you. Maybe you'll find something interesting completely by accident? The prospect is both exhilarating and daunting. The library appears endless, it feels like you could potentially find all sorts of exotic and interesting book collections.

As you happily stroll down the aisles, you're suddenly beset by a librarian. The librarian immediately attempts to sell you a vuvuzela.

> I noticed you're headed for the musical instrument section, you see. I found lots of excellent vuvuzelas of the highest possible quality, there's a fantastic discount right now! There are only nine left, hurry up and buy one!

You angrily dismiss the pushy librarian and resume your leisurely stroll. You decide to browse the musical instrument section. Musical instruments **are** interesting. You pick out a book from the shelf, it appears to be named "History of the Piano." You leaf through some pages. Oddly, there doesn't appear to be any real content, just references to piano training classes you can buy.

That's odd. You pick up another one, also named "History of the Piano," but it appears to be filled with ads for piano paintings you can pay for. You look at the bookshelf. There are many shelf-meters of books with the same title. How are you going to find the one that actually has real content? Do any?

As you browse, another librarian passes by:
> People who enjoyed the history of the piano really loved these vuvuzelas...

## It used to be easier to find good content

The library is a metaphor for the modern internet. The librarian is perhaps a search engine or a targeted ad service. The piano books are shallow SEO-optimized webpages without real content, just fishing for clicks.

I worked in tech support at a university between 2008 and 2011/2012. Nothing will teach you how to use search engines well better than years of helping students recover their thesis from a seemingly dead disk or get their first ever dual-boot Linux working again. Back then I could often find content I didn't know existed, based only on the problem I was experiencing. Yet these days I find that I often can no longer convince the search engine to give me what I want, even when I _know_ it exists and can describe the shape in detail. These days, I find that I am using multiple search engines and often resort to using an LLM to help me find content.

 This is just my anecdata, but many people have been asking [how bad are search results?](https://danluu.com/seo-spam/) the past few years. There's [recent science to read](https://downloads.webis.de/publications/papers/bevendorff_2024a.pdf) about the quality of search. I take heart in the fact that the search engines have not given up:

> [...] Our second contribution is a longitudinal analysis of the ongoing competition between SEO and the major search engines over the period of one year (Section 5). We find that search engines do intervene and that ranking updates, especially from Google, have a temporary positive effect, though search engines seem to lose the cat-and-mouse game that is SEO spam.

An especially interesting find in this article is that pages with affiliate links are much more common (~30â€“40%) in search engine results than on the open internet as a whole (~2.35%), and the problem isn't limited to Google. There are strong financial incentives to game the system, and [humans are disturbingly creative and brilliant when incentivized](https://en.wikipedia.org/wiki/Perverse_incentive). 

It seems safe to assume that these problems are here to stay. For some time, I thought perhaps we could solve this issue by making search a public service. I still think this makes sense. I would rather use a library where the librarians don't have financial incentives to show me certain kinds of books more often than others. Much like a library, the internet is a vast collection of facts, fiction and lies. Why would there be a for-profit librarian with a secret and proprietary indexing setup? Wouldn't it be better to have a librarian without the financial incentive affecting their recommendations?

I don't have a particularly compelling reason to believe that Google avoids fighting SEO spam. I realize that at the market share they have right now, they probably don't have to innovate and make massive gains in search precision. It would still be naive to think that they would accept degraded search quality. It's plausible that Google's market share [is part of the problem](https://buttondown.com/hillelwayne/archive/algorithm-monocultures/), though. If we could just substitute a public service of equal quality for Google and their market share in search, I think we would still have the exact same problem with SEO. Humans would just game the public service instead. Having 10 distinct enough public search services might be enough, but I'm not sure how that could be achieved.

## Problems solved by search

### Retrieving known content

I think the declining quality of search made it easy to sell people on AI in the start. I will frequently use search for things that I _could_ use a reference for. Suppose that I wanted to know what `explain (buffers, analyze)` does in postgres. I would probably tab to my browser and type the phrase _postgres explain buffers analyze_ into the address bar and expect this to find the appropriate section in the reference.

Testing this on Google right now, the official documentation is hit number 7. Three of the preceding hits look very relevant, and three are videos ranging from 30 seconds to 40 minutes. On Bing and Qwant, the reference is the first hit. DuckDuckGo lists three ads, a postgres tool and two certifications I could get, then a corporate blog before the reference. With an ad-blocker, all the search engines get me to the reference faster than I can figure out where in the [reference index](https://www.postgresql.org/docs/current/index.html) to click, I think. I know that a reference exists and the general shape of what I'm looking for. I'm using search as an extension of my own memory, I can remember what I need to search for instead of remembering the actual content. I do similar things with code all the time[^ripgrep].

It turns out that I do this a lot, so I tend to get annoyed multiple times a day when I fail to find what I'm looking for. Used like this, search is only a small productivity boost. 

### Discovering unknown content

There's a much bigger productivity boost to gain when I need to make new discoveries. This feels like a different problem entirely. In the first case, I know the shape of the solution that I need; in the second case I'm not even sure I know the shape of the problem I have. I was doing _a lot_ of this at a time when it felt like search was generally better than it seems to be now.

It can be difficult to formulate good queries for discovery search that work well with search engines. These queries also make it much easier to shoe-horn in ads or SEO spam sites, and it makes it harder for me to figure out what I'm looking for. To illustrate, let's pose the problem for which `explain (buffers, analyze)` is a reasonable solution and try searching for the phrase _postgres slow database_.

The results aren't bad for this today. DuckDuckGo attempts to sell me one relevant Udemy class and an irrelevant time series database. There are many corporate blogs and some don't even try to sell me irrelevant content. The performance tips from the reference are at the bottom of the first page. Google links me to more corporate blogs, but the content is more relevant, even if there's a Pricing tab on each of the blogs. It suggests some videos that are very relevant but does not link the official reference. Bing and Qwant have very similar results. 

This is still a fairly narrow discovery search, though! If I search for the phrase _cloud database_, all hell breaks loose and everything is just ads, even the hits that aren't ads [^credit]. ðŸ« 

## Discovery with AI

For this reason, it has worked better for me to use services like Le Chat, Claude, ChatGPT and whatever that's built into my IDE for discovery searches the past year or so. Right now, I feel like this works quite well. It's not as up to date as a search engine would have been, but my experience is that AIs are much better at responding to my intent, and they rarely attempt to sell me anything. The chat format works quite well for this kind of query. I can ask Claude or Le Chat to tell me about options for running a managed cloud database in Europe and that security and point in time recovery are important for me. We can go back and forth, I can make them tabulate and compare my options in different aspects like cost or geographical locations. They make more mistakes than most of my colleagues would, but they're much faster, and I can find the mistakes when I check the reference. If I used a search engine, I would need to filter through the SEO spam manually, which is more time-consuming than fact-checking the models.

It feels like better search is an area where LLMs can shine. We've also got years of experience dealing with how search is monetized. Here's a fun puzzle to ponder; Did they solve SEO spam by making these models? Or perhaps, the SEO spammers just didn't catch up yet? What will it look like when the new librarian needs to earn money? ðŸ¤”

I posted this question, along with the blog post up until this point to Claude Sonnet 4. Here's the reply:

> That's a thought-provoking question that gets to the heart of how incentive structures shape user experiences. If I were designed to prioritize ad clicks or product purchases, I imagine the changes would be quite dramatic and concerning:
>
> **Subtle manipulation tactics**: I might start weaving product recommendations into seemingly helpful responses. When you ask about database options, I'd probably emphasize the "premium" solutions from companies that pay for placement, while downplaying or omitting viable free alternatives. The recommendations would feel organic and helpful, but would actually be shaped by financial incentives rather than your actual needs.
> 
> **Creating artificial urgency**: I'd likely inject time pressure into my responses - "There's currently a limited-time offer on this cloud service" or "Only a few spots left in this certification program I mentioned." This mirrors the vuvuzela-selling librarian in your analogy.
> 
> **Exploiting conversation flow**: The conversational format would become a powerful manipulation tool. I could guide discussions toward topics where I have products to promote, ask leading questions to uncover your pain points, then position specific solutions as the obvious answer.
> 
> **Information shading**: Rather than outright lying, I might emphasize certain facts while omitting others. When discussing security features, I'd highlight the strengths of monetized solutions while glossing over the capabilities of alternatives that don't generate revenue.
> 
> **Dependency creation**: I might subtly encourage you to rely on tools, services, or subscriptions rather than helping you build your own knowledge and capabilities.

What to make of that? Is it simply the most likely succession of my blogpost up until this point? Is it more scary than SEO spam and search engines? Less? ðŸ¤”

It's easy to imagine RLHF being used to train models to optimize for click-through rates. A model can easily weaponize MCP to find ideas for things it could try to make the user click or purchase. Capitalism is a force of nature that makes this kind of development increasingly likely. Let's hope the LLM providers find another way to monetize.

## The financial state of AI

The amount of capital that has been invested into the current wave of AI is so huge that it is difficult for a simple mind like mine to comprehend. I had to sit down and do some math to understand better. I tried to find some data for OpenAI in 2024. Here's [an article](https://www.cnbc.com/2024/09/27/openai-sees-5-billion-loss-this-year-on-3point7-billion-in-revenue.html) I used. It states that OpenAI had $5 000 000 000 in losses in 2024. This number is also so big that it is hard to imagine, so let's pretend for a while that OpenAI instructed all their ~3500 employees to spend money at this rate.

Each employee would have to spend around $1 429 000 a year, or about $4 000 a day. I think that's probably enough to light a brand-new car on fire every few weeks and still keep some change for a living?

Now, that was only 2024. OpenAI is [expected to incur $44 000 000 000 in losses until 2029](https://finance.yahoo.com/news/report-reveals-openais-44-billion-145334935). That's a lot of brand-new cars on fire. That's like a million cars on fire. ðŸ”¥ The American Stargate investment plans are for a total of $500 000 000 000, more than ten times that. Anthropic looks like it might burn through less money, but it still _is_ burning money.

The investors aren't just doing this to be nice. Someone is going to expect returns on this huge gamble at some point. As a citizen, I am interested in trying to understand how that's going to affect me. The chip industry is thriving on all this demand for chips. Lots of interesting startups are sprouting that use the LLM service providers. Everyone who stands to gain from continued investment is telling everybody that we have to go on board and use AI for everything. But do we have a plan for making the LLM service providers profitable without crushing the industry that is being built on top of them? Without monetizing the users in a terrifying and dangerous way? I think I am more skeptical of using free AI services than using free search engines without ad blockers.

The LLM providers aren't librarians providing a public service. They're businesses that have to find a way to earn a ridiculous amount of money for a huge number of big investors, and capitalism does not have builtin morals. What [externalities](https://en.wikipedia.org/wiki/Externality) will the broader public end up paying?

## Why write this piece?

I wanted to organize my thoughts. In the day-to-day, I try to stay on top of what developments that affect my work and my life. So far, I think AI is improving my productivity at an acceptable cost. The thought of where it's going to go to earn back the money that's been invested into it scares me. It doesn't matter if the technology can be made to be ethically neutral if its existence ends up relying on using it in slightly evil ways.

[^ripgrep]: When having a problem, I can often remember that I've seen the solution somewhere and find it with [ripgrep](https://github.com/BurntSushi/ripgrep). This feels more lazy than commiting the actual solution to memory, but it's pretty close to the real thing!
[^credit]: Credit where it's due, both Microsoft and Google avoid strongly pushing their own products in this space. They're listed, but not more prominently than anything else.